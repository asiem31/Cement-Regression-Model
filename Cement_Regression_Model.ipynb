{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cement Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Building a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets download all the dependencies we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: tensorflow_cpu==2.15.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_cpu==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (4.25.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\adam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow_cpu==2.15.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tensorflow_cpu==2.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets import pandas, numpy, and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets download the data and read it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "file = 'https://cocl.us/concrete_data'\n",
    "concrete_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should separate the data into predictors and the target. The strength column is the target. All the other columns are the predictors. Here we create a variable that specifically returns the column names from the dataframe so we can easily perform operations that assign predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_colms = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_colms[concrete_data_colms != 'Strength']]\n",
    "target = concrete_data['Strength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets import the rest of the packages we need and actually build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concrete_regression_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(predictors.shape[1],)))     #expect batches of 8 dimensional vectors as input\n",
    "    model.add(Dense(10, activation='relu'))     #one hidden layer, 10 nodes, ReLU activation function\n",
    "    model.add(Dense(1))     #output layer\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets call the function and test/train it but hold 30% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = concrete_regression_model()\n",
    "\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=50)     #used 50 epochs for training, validation_split=0.3 means 30% of data is set aside for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to import the mean_squared_error function from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train 50 times and compose a list of the resulting mean squared error that comes from every run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = []\n",
    "\n",
    "for i in range(50):\n",
    "    model.fit(predictors, target, validation_split=0.3, epochs=50)\n",
    "    predictions = model.predict(predictors)     #we get the predictions using the predict() function\n",
    "    mse = mean_squared_error(target, predictions)     #compare target values to predicted values\n",
    "    mse_list.append(mse)     #add the resulting mean squared error to a list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_list)\n",
    "\n",
    "print(len(mse_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets calculate the mean and standard deviation of the mean squared errors in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_mse_list = np.mean(mse_list)\n",
    "std_of_mse_list = np.std(mse_list)\n",
    "\n",
    "print(mean_of_mse_list)\n",
    "print(std_of_mse_list)\n",
    "\n",
    "# In my runs I got mean = 65.485 and standard deviation = 14.172\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Normalize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets normalize the predictors and feed it into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_normalized = (predictors - predictors.mean()) / predictors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run this 50 times once again but this time with normalized data as opposed to raw data.\n",
    "\n",
    "mse_list_2 = []\n",
    "\n",
    "for i in range(50):\n",
    "    model.fit(predictors_normalized, target, validation_split=0.3, epochs=50)\n",
    "    predictions = model.predict(predictors_normalized) \n",
    "    mse = mean_squared_error(target, predictions)     \n",
    "    mse_list_2.append(mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_list_2)\n",
    "print(len(mse_list_2))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_mse_list_2 = np.mean(mse_list_2)\n",
    "std_of_mse_list_2 = np.std(mse_list_2)\n",
    "\n",
    "print(mean_of_mse_list_2)\n",
    "print(std_of_mse_list_2)\n",
    "\n",
    "# In my run I got mean = 56.799 and standard deviation = 36.299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that the mean of the mean squared errors is smaller than that in Part A. Part A's mean was 65.485 and Part B's mean was 36.299. This indicates the mean squared error was smaller on average after I normalized the predictors data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Increase the Number of Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do 100 epochs and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list_3 = []\n",
    "\n",
    "for i in range(50):\n",
    "    model.fit(predictors_normalized, target, validation_split=0.3, epochs=100)\n",
    "    predictions = model.predict(predictors_normalized) \n",
    "    mse = mean_squared_error(target, predictions)     \n",
    "    mse_list_3.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_list_3)\n",
    "print(len(mse_list_3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_mse_list_3 = np.mean(mse_list_3)\n",
    "std_of_mse_list_3 = np.std(mse_list_3)\n",
    "\n",
    "print(mean_of_mse_list_3)\n",
    "print(std_of_mse_list_3)\n",
    "\n",
    "# In my run I got mean = 67.618 and standard deviation = 27.701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that the mean compared to Part B is actually a little bit higher. In Part B I got mean = 56.799 and in Part C I got mean = 67.618"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Increase the Number of Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's repeat Part B, but with more hidden layers as opposed to more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets make a new model function that has 3 hidden layers as opposed to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concrete_regression_model_2():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(predictors.shape[1],)))     #expect batches of 8 dimensional vectors as input\n",
    "    model.add(Dense(10, activation='relu'))    \n",
    "    model.add(Dense(10, activation='relu'))    \n",
    "    model.add(Dense(10, activation='relu'))     #3 hidden layers, 10 nodes each, ReLU activation function\n",
    "    model.add(Dense(1))     #output layer\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize this function in a model_2 variable then we will train 50 times and compose a list of the resulting mean squared errors that come from every run in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1664.2968 - val_loss: 1187.9579\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1629.2975 - val_loss: 1151.8136\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1576.1948 - val_loss: 1097.7520\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1494.6527 - val_loss: 1017.4120\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1368.9597 - val_loss: 896.9727\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1182.4487 - val_loss: 726.1185\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 933.0164 - val_loss: 534.0384\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 663.3149 - val_loss: 360.7517\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 456.7949 - val_loss: 248.7241\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 343.6378 - val_loss: 199.3941\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 299.7405 - val_loss: 179.8582\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 276.0862 - val_loss: 170.9902\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 257.9556 - val_loss: 162.5863\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.7540 - val_loss: 156.5567\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 233.1664 - val_loss: 153.4354\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.2706 - val_loss: 149.6533\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.3320 - val_loss: 147.5859\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.3845 - val_loss: 146.1659\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.7202 - val_loss: 145.1705\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.7968 - val_loss: 143.8988\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.0159 - val_loss: 143.3614\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.4660 - val_loss: 143.4929\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.9284 - val_loss: 143.7203\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5293 - val_loss: 145.2473\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9521 - val_loss: 144.5284\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2416 - val_loss: 144.9531\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5614 - val_loss: 145.5887\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3338 - val_loss: 146.9991\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2899 - val_loss: 147.4173\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9025 - val_loss: 146.5121\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4936 - val_loss: 146.9549\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5737 - val_loss: 148.3647\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9553 - val_loss: 148.2021\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1194 - val_loss: 149.9037\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1968 - val_loss: 150.6139\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5337 - val_loss: 151.2006\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0281 - val_loss: 151.1346\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7224 - val_loss: 152.0874\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3165 - val_loss: 153.6023\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1784 - val_loss: 155.5385\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.5719 - val_loss: 151.1834\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3486 - val_loss: 154.2881\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5629 - val_loss: 154.1655\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.6292 - val_loss: 155.6976\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.8620 - val_loss: 154.0468\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.1772 - val_loss: 156.5797\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.8536 - val_loss: 155.5209\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6213 - val_loss: 154.5966\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.7818 - val_loss: 155.0082\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.0987 - val_loss: 156.8296\n",
      "33/33 [==============================] - 0s 934us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.1215 - val_loss: 160.8535\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.0986 - val_loss: 155.7632\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.9059 - val_loss: 155.9028\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.6547 - val_loss: 157.7671\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.9076 - val_loss: 158.9788\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.2618 - val_loss: 154.3734\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.8960 - val_loss: 156.0271\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.8267 - val_loss: 158.0986\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.9258 - val_loss: 155.2925\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.0711 - val_loss: 157.6437\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.0637 - val_loss: 157.6834\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.5824 - val_loss: 155.7993\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.7970 - val_loss: 157.3463\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.9032 - val_loss: 154.6270\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.2777 - val_loss: 154.6552\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.2443 - val_loss: 156.2660\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.4655 - val_loss: 155.1439\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.2405 - val_loss: 154.6658\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.3256 - val_loss: 156.3395\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.5308 - val_loss: 154.7593\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.7081 - val_loss: 152.2346\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 111.7869 - val_loss: 154.7760\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110.7775 - val_loss: 153.1708\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.8508 - val_loss: 151.3326\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.8423 - val_loss: 153.5035\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 107.9524 - val_loss: 151.8447\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 107.3036 - val_loss: 152.8680\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 106.4735 - val_loss: 151.7634\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 106.0394 - val_loss: 150.7941\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 104.7098 - val_loss: 154.2075\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 103.7754 - val_loss: 149.8229\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 103.1533 - val_loss: 150.0265\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 102.3672 - val_loss: 150.3497\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 101.5195 - val_loss: 149.1247\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 100.7578 - val_loss: 148.5182\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 99.9460 - val_loss: 146.3854\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 99.2651 - val_loss: 147.7217\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 98.1853 - val_loss: 149.7028\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 97.7707 - val_loss: 147.5619\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 96.7995 - val_loss: 146.2893\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 96.5727 - val_loss: 144.2681\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 96.2459 - val_loss: 145.7925\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 95.0287 - val_loss: 147.5137\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 94.0969 - val_loss: 141.9557\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 94.7573 - val_loss: 144.2418\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 92.9964 - val_loss: 144.0516\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 91.8531 - val_loss: 141.9473\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 91.4120 - val_loss: 141.7588\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 90.7163 - val_loss: 140.3731\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 89.8447 - val_loss: 141.9805\n",
      "33/33 [==============================] - 0s 872us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 88.9300 - val_loss: 138.6948\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 88.1198 - val_loss: 140.1468\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 87.1794 - val_loss: 143.5244\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 86.7562 - val_loss: 138.0861\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 85.7673 - val_loss: 141.0060\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 85.0789 - val_loss: 138.1219\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 84.0581 - val_loss: 138.3620\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 83.9467 - val_loss: 132.4351\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 82.6493 - val_loss: 141.8086\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 82.2348 - val_loss: 133.3254\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 81.2466 - val_loss: 133.4646\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 80.6917 - val_loss: 135.1351\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 79.6730 - val_loss: 134.1187\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 78.7929 - val_loss: 131.8463\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 78.4883 - val_loss: 131.7017\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 77.4641 - val_loss: 131.9693\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 77.8291 - val_loss: 124.2886\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 76.2701 - val_loss: 132.1460\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 75.9048 - val_loss: 125.0744\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 74.2642 - val_loss: 125.1330\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 73.4604 - val_loss: 126.9568\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 72.9431 - val_loss: 121.3676\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 72.0611 - val_loss: 123.5932\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 71.0159 - val_loss: 119.6422\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 70.3461 - val_loss: 122.7075\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 69.5705 - val_loss: 120.4036\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 68.2290 - val_loss: 118.0201\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 67.6366 - val_loss: 114.6864\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 66.5353 - val_loss: 114.1689\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 66.0331 - val_loss: 115.6692\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 65.4169 - val_loss: 109.0765\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 65.6109 - val_loss: 112.0986\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 63.0442 - val_loss: 111.4655\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 62.2829 - val_loss: 108.8207\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 62.5900 - val_loss: 105.4806\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 60.7113 - val_loss: 113.9216\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 59.6891 - val_loss: 106.7769\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 58.9099 - val_loss: 110.3876\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 58.4120 - val_loss: 110.4461\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 57.1505 - val_loss: 107.0859\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 56.7698 - val_loss: 110.5816\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 55.7887 - val_loss: 106.3278\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 54.8159 - val_loss: 109.0732\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 54.4247 - val_loss: 106.0773\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 53.5979 - val_loss: 111.1968\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 52.9200 - val_loss: 104.6886\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 51.9002 - val_loss: 108.5754\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 51.4609 - val_loss: 101.3220\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 51.2435 - val_loss: 112.5448\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 50.3823 - val_loss: 103.9013\n",
      "33/33 [==============================] - 0s 935us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 49.9604 - val_loss: 104.6309\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 49.4834 - val_loss: 114.6209\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 48.3972 - val_loss: 107.3158\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 47.9425 - val_loss: 109.2819\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 47.2192 - val_loss: 115.1961\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 46.6969 - val_loss: 111.0676\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 46.0246 - val_loss: 113.3249\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 45.7505 - val_loss: 116.0168\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 45.2769 - val_loss: 117.3333\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 44.7469 - val_loss: 131.4668\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 44.4794 - val_loss: 116.1084\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 44.2931 - val_loss: 121.2945\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 43.3462 - val_loss: 123.5342\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 42.8908 - val_loss: 129.0285\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 42.3058 - val_loss: 127.9970\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 42.1381 - val_loss: 137.2575\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 41.4887 - val_loss: 125.9782\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 41.0758 - val_loss: 139.1304\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 40.9387 - val_loss: 136.1938\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 40.6534 - val_loss: 135.8999\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 40.1323 - val_loss: 133.3996\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 40.8371 - val_loss: 142.5933\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 40.4342 - val_loss: 149.3433\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 39.6877 - val_loss: 137.1793\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 39.5761 - val_loss: 143.7993\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 39.2980 - val_loss: 148.4600\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 38.8438 - val_loss: 145.0181\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 38.7305 - val_loss: 146.8795\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 38.4756 - val_loss: 149.0431\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 38.2635 - val_loss: 160.4253\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 38.3924 - val_loss: 143.9868\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 38.2495 - val_loss: 153.3997\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.9357 - val_loss: 157.2951\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.7341 - val_loss: 152.2891\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.2583 - val_loss: 168.8537\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.4788 - val_loss: 159.3070\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.3159 - val_loss: 163.3823\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.1694 - val_loss: 161.2348\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.0747 - val_loss: 156.8751\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.9933 - val_loss: 159.7166\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.0774 - val_loss: 153.8769\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 37.1829 - val_loss: 170.1959\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.5607 - val_loss: 166.1228\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.5281 - val_loss: 164.1649\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.5236 - val_loss: 160.7896\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.5170 - val_loss: 175.6546\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.6209 - val_loss: 156.0553\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.5154 - val_loss: 159.6221\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.9797 - val_loss: 166.0735\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 36.0724 - val_loss: 164.1693\n",
      "33/33 [==============================] - 0s 928us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 36.4556 - val_loss: 172.4537\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.9898 - val_loss: 162.7039\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.7178 - val_loss: 167.8720\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.5610 - val_loss: 165.5427\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.7924 - val_loss: 165.8734\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.5111 - val_loss: 172.4928\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 35.8137 - val_loss: 169.4501\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.3705 - val_loss: 163.9196\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.5948 - val_loss: 162.7117\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.4133 - val_loss: 171.7595\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.0029 - val_loss: 160.8130\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.4214 - val_loss: 164.4388\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.7758 - val_loss: 179.8129\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35.1241 - val_loss: 171.9001\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.7892 - val_loss: 168.1919\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 35.0127 - val_loss: 172.3539\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 35.0322 - val_loss: 170.6309\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.8110 - val_loss: 174.4140\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.6497 - val_loss: 173.4779\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.7006 - val_loss: 167.6121\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.3508 - val_loss: 177.8281\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.4409 - val_loss: 163.3610\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.8200 - val_loss: 177.3601\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.4074 - val_loss: 176.1571\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.7237 - val_loss: 163.5996\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.7535 - val_loss: 182.8736\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.7106 - val_loss: 166.2388\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.8140 - val_loss: 165.4341\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.2879 - val_loss: 171.6747\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.1972 - val_loss: 181.3241\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.1341 - val_loss: 168.7636\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.2603 - val_loss: 169.3326\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 34.4556 - val_loss: 176.7085\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.4522 - val_loss: 164.8657\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.1701 - val_loss: 179.7509\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.9356 - val_loss: 178.6317\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.9043 - val_loss: 164.2330\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.8945 - val_loss: 174.2113\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.7311 - val_loss: 169.9295\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.7926 - val_loss: 174.2163\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.8985 - val_loss: 187.9296\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.9081 - val_loss: 170.2850\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.5530 - val_loss: 176.7272\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.8803 - val_loss: 178.2276\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.9894 - val_loss: 166.7145\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.6751 - val_loss: 173.1283\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.4849 - val_loss: 169.9563\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.7110 - val_loss: 173.6953\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.5098 - val_loss: 176.1141\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.6682 - val_loss: 174.8303\n",
      "33/33 [==============================] - 0s 904us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 33.4125 - val_loss: 179.2887\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.5301 - val_loss: 174.9221\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.4290 - val_loss: 194.4568\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.7891 - val_loss: 168.8937\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 34.0081 - val_loss: 164.3863\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.4266 - val_loss: 178.8326\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.1543 - val_loss: 174.2258\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.6010 - val_loss: 173.2929\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.4520 - val_loss: 180.1347\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.5397 - val_loss: 182.4955\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.1304 - val_loss: 174.7446\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.5150 - val_loss: 172.0568\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.0780 - val_loss: 186.4120\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.2003 - val_loss: 166.9108\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.1924 - val_loss: 182.7830\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.4443 - val_loss: 180.5566\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.9252 - val_loss: 171.2376\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.4615 - val_loss: 182.5648\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.4228 - val_loss: 187.8673\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.9078 - val_loss: 179.3454\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.2515 - val_loss: 175.1154\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.9686 - val_loss: 181.5046\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.1355 - val_loss: 181.9342\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.9945 - val_loss: 169.3884\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.3893 - val_loss: 177.6000\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 33.2587 - val_loss: 176.5001\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.8653 - val_loss: 177.9317\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.1477 - val_loss: 172.7043\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.4721 - val_loss: 191.1613\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.5667 - val_loss: 168.4859\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 33.1095 - val_loss: 180.3441\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.8108 - val_loss: 189.4524\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.6541 - val_loss: 171.4429\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.6998 - val_loss: 177.9673\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.6189 - val_loss: 174.2922\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.9261 - val_loss: 179.0972\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.4980 - val_loss: 179.6620\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.8908 - val_loss: 183.1081\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.8452 - val_loss: 186.0152\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.5304 - val_loss: 168.6550\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.9713 - val_loss: 190.8857\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.9107 - val_loss: 181.6419\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.8581 - val_loss: 187.3473\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.5412 - val_loss: 184.7213\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.3938 - val_loss: 172.4887\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.4734 - val_loss: 185.8646\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.3983 - val_loss: 181.5053\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.4730 - val_loss: 183.7181\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.2580 - val_loss: 182.7585\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.4156 - val_loss: 187.6035\n",
      "33/33 [==============================] - 0s 904us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 32.1992 - val_loss: 167.9396\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.6030 - val_loss: 189.6760\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.6036 - val_loss: 180.1689\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.6423 - val_loss: 175.0299\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.4833 - val_loss: 187.0259\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.3979 - val_loss: 186.0745\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.4435 - val_loss: 165.7966\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.3386 - val_loss: 198.6645\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.3953 - val_loss: 173.2928\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.1286 - val_loss: 185.3792\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.2343 - val_loss: 193.8743\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.4469 - val_loss: 178.1068\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.1381 - val_loss: 178.5477\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.2723 - val_loss: 174.3450\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.6278 - val_loss: 184.7632\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.6811 - val_loss: 194.0109\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.1587 - val_loss: 182.4699\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.3590 - val_loss: 182.8495\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.2478 - val_loss: 182.9713\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.3693 - val_loss: 173.7808\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.2301 - val_loss: 178.7526\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.1631 - val_loss: 178.2840\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.0850 - val_loss: 190.2562\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.9679 - val_loss: 174.6147\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.0228 - val_loss: 181.9308\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.9652 - val_loss: 186.1569\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.2665 - val_loss: 194.1428\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.0990 - val_loss: 172.1381\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.8620 - val_loss: 184.1078\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.7393 - val_loss: 178.4524\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.9313 - val_loss: 182.6637\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.9310 - val_loss: 168.2106\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.4779 - val_loss: 190.7515\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.9491 - val_loss: 189.1379\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.6583 - val_loss: 184.0697\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.9043 - val_loss: 180.6376\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.2622 - val_loss: 197.4614\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.5132 - val_loss: 195.3767\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.0736 - val_loss: 181.7672\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.6958 - val_loss: 185.9891\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.8616 - val_loss: 185.0786\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 31.6944 - val_loss: 189.4465\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.1914 - val_loss: 200.1889\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.9838 - val_loss: 188.3604\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.8777 - val_loss: 182.0919\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.7492 - val_loss: 177.8632\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.6195 - val_loss: 185.6648\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.8176 - val_loss: 182.3195\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.9247 - val_loss: 188.2995\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.8772 - val_loss: 187.3910\n",
      "33/33 [==============================] - 0s 902us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 31.7503 - val_loss: 177.5827\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 32.3852 - val_loss: 191.2900\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.7343 - val_loss: 177.2778\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.3061 - val_loss: 186.8016\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.1320 - val_loss: 197.1848\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.7179 - val_loss: 194.3297\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.8264 - val_loss: 190.0011\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.6642 - val_loss: 194.5777\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.5799 - val_loss: 181.3812\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.8514 - val_loss: 175.0140\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.3542 - val_loss: 194.0417\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.6200 - val_loss: 194.7946\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.4947 - val_loss: 185.4783\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.9796 - val_loss: 172.8921\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.8664 - val_loss: 186.2205\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.4638 - val_loss: 192.9525\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.6990 - val_loss: 193.0598\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.4424 - val_loss: 189.1420\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.8331 - val_loss: 190.1102\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.5227 - val_loss: 179.6461\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.8586 - val_loss: 199.0691\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32.1745 - val_loss: 202.7265\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.9884 - val_loss: 191.9972\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.5609 - val_loss: 179.3443\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.5033 - val_loss: 185.5200\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.4571 - val_loss: 186.6660\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.5141 - val_loss: 182.6915\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.2220 - val_loss: 201.2502\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.7632 - val_loss: 195.2048\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.4223 - val_loss: 181.5309\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.3375 - val_loss: 184.3218\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.2790 - val_loss: 184.6484\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.3526 - val_loss: 193.4064\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.4587 - val_loss: 196.4702\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.1946 - val_loss: 179.6744\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.3429 - val_loss: 191.0961\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.9606 - val_loss: 188.8210\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.0786 - val_loss: 187.4048\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.1562 - val_loss: 188.8615\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.0770 - val_loss: 186.2099\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.1395 - val_loss: 194.9130\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.3341 - val_loss: 193.1410\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.1728 - val_loss: 199.6767\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.4086 - val_loss: 188.6950\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.3658 - val_loss: 179.3027\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.2587 - val_loss: 195.9414\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.3879 - val_loss: 181.4271\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.1202 - val_loss: 196.1740\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.2916 - val_loss: 190.9515\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.0994 - val_loss: 194.0998\n",
      "33/33 [==============================] - 0s 943us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 31.0803 - val_loss: 179.2344\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.9511 - val_loss: 199.3103\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 31.2424 - val_loss: 189.3254\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.4135 - val_loss: 189.6348\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.8802 - val_loss: 196.2775\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.9270 - val_loss: 174.4478\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.4796 - val_loss: 200.4344\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.0547 - val_loss: 188.3556\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.9977 - val_loss: 187.7750\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.1789 - val_loss: 194.1375\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.9745 - val_loss: 192.2125\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.8602 - val_loss: 202.3265\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.1789 - val_loss: 195.8924\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.7724 - val_loss: 186.7622\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.6668 - val_loss: 197.5756\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.5841 - val_loss: 197.8324\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.1683 - val_loss: 198.8037\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.7637 - val_loss: 193.2967\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.7858 - val_loss: 192.4226\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.6918 - val_loss: 194.0193\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.0833 - val_loss: 201.7263\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.9029 - val_loss: 189.2154\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.7964 - val_loss: 202.5175\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.7295 - val_loss: 188.0295\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.6981 - val_loss: 185.3052\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.0602 - val_loss: 184.3568\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.9188 - val_loss: 176.2361\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.0198 - val_loss: 212.6582\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.4298 - val_loss: 198.4633\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.7238 - val_loss: 188.2139\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.5170 - val_loss: 200.9691\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.8137 - val_loss: 186.6916\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 30.7985 - val_loss: 191.2632\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.8501 - val_loss: 189.0148\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.4960 - val_loss: 190.1498\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.8602 - val_loss: 195.1199\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.6857 - val_loss: 190.4600\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.4844 - val_loss: 187.4748\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.6678 - val_loss: 200.1727\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.5811 - val_loss: 178.9878\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.7718 - val_loss: 192.9523\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.5945 - val_loss: 196.3761\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.3281 - val_loss: 184.5409\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.6544 - val_loss: 187.5743\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.4450 - val_loss: 193.6778\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.7670 - val_loss: 175.3970\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.5316 - val_loss: 191.2475\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31.0900 - val_loss: 201.6675\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.3810 - val_loss: 188.4555\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.3963 - val_loss: 192.8137\n",
      "33/33 [==============================] - 0s 904us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 30.6079 - val_loss: 193.8382\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.3994 - val_loss: 190.6599\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.5675 - val_loss: 192.7329\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.4387 - val_loss: 194.3378\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.4003 - val_loss: 195.0331\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.4845 - val_loss: 199.3829\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.7074 - val_loss: 195.5596\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.5212 - val_loss: 184.2323\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.4170 - val_loss: 199.0940\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31.0379 - val_loss: 171.9035\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.3951 - val_loss: 206.5068\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.5515 - val_loss: 193.5364\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.2864 - val_loss: 191.9619\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.5650 - val_loss: 191.8472\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.2583 - val_loss: 194.0869\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.3301 - val_loss: 188.1062\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.3295 - val_loss: 197.1351\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.2932 - val_loss: 188.4060\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.3288 - val_loss: 186.9827\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.3611 - val_loss: 189.9949\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.1817 - val_loss: 194.5092\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.1125 - val_loss: 180.4762\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.1748 - val_loss: 188.9459\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.1592 - val_loss: 191.6301\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.2766 - val_loss: 186.7772\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.1116 - val_loss: 181.6040\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.6190 - val_loss: 190.1269\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.4224 - val_loss: 187.7664\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.0845 - val_loss: 189.2911\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.6853 - val_loss: 175.6629\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.2540 - val_loss: 196.0865\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.9474 - val_loss: 178.9335\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.5027 - val_loss: 211.6369\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.4997 - val_loss: 187.8162\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.9836 - val_loss: 187.3145\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.2060 - val_loss: 180.2399\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.3859 - val_loss: 190.2536\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7829 - val_loss: 194.4992\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.0075 - val_loss: 195.3545\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.0767 - val_loss: 191.6204\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.0546 - val_loss: 192.2628\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.9514 - val_loss: 193.0751\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 30.2207 - val_loss: 192.2486\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.8906 - val_loss: 181.1245\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.9957 - val_loss: 191.2913\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.9653 - val_loss: 185.0725\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.0268 - val_loss: 186.1889\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.8675 - val_loss: 182.8043\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.9413 - val_loss: 192.2614\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.0306 - val_loss: 187.5145\n",
      "33/33 [==============================] - 0s 906us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 29.9659 - val_loss: 182.4945\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.0022 - val_loss: 202.7614\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.9802 - val_loss: 173.3407\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.8862 - val_loss: 198.4422\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.8288 - val_loss: 179.7614\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.7906 - val_loss: 189.1908\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.8417 - val_loss: 184.5434\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.3251 - val_loss: 197.0398\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.9079 - val_loss: 183.2065\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.9273 - val_loss: 182.1988\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.9050 - val_loss: 191.2769\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.8361 - val_loss: 182.0355\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.7842 - val_loss: 180.5374\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.7242 - val_loss: 188.0986\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7695 - val_loss: 188.7904\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.8648 - val_loss: 192.0930\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.8860 - val_loss: 186.8353\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.8838 - val_loss: 181.3929\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.0362 - val_loss: 185.5715\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.1229 - val_loss: 189.1342\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 29.5951 - val_loss: 184.3694\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.4882 - val_loss: 171.4465\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.4027 - val_loss: 199.9084\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.8488 - val_loss: 169.2006\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.2944 - val_loss: 181.3985\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.6048 - val_loss: 193.2301\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.5625 - val_loss: 182.6359\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.8711 - val_loss: 167.6371\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.5681 - val_loss: 179.5771\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.2846 - val_loss: 186.6301\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7363 - val_loss: 192.3517\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.0586 - val_loss: 183.1499\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7651 - val_loss: 167.7639\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.6332 - val_loss: 196.0365\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.7628 - val_loss: 184.6814\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.5607 - val_loss: 179.1908\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.5284 - val_loss: 188.9253\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.5869 - val_loss: 183.2016\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.6382 - val_loss: 179.7821\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.8050 - val_loss: 183.8493\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.5783 - val_loss: 186.2060\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.3203 - val_loss: 180.4451\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.7317 - val_loss: 173.2369\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.4373 - val_loss: 192.1277\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.5305 - val_loss: 178.8086\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.6374 - val_loss: 181.2791\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.5652 - val_loss: 189.6733\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3509 - val_loss: 182.4346\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 30.0652 - val_loss: 177.5306\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7673 - val_loss: 179.4142\n",
      "33/33 [==============================] - 0s 852us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 29.3719 - val_loss: 188.3853\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7237 - val_loss: 188.6942\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.4106 - val_loss: 185.6734\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3705 - val_loss: 187.0264\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.6326 - val_loss: 179.2274\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.3557 - val_loss: 180.0863\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.1302 - val_loss: 194.3424\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.5289 - val_loss: 176.3632\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.4209 - val_loss: 183.7252\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.6285 - val_loss: 192.8563\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.2476 - val_loss: 182.2747\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.2275 - val_loss: 185.1819\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.5324 - val_loss: 194.9686\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.5518 - val_loss: 189.6761\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7443 - val_loss: 179.8620\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.3452 - val_loss: 176.7036\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.2160 - val_loss: 191.3834\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.5887 - val_loss: 201.8623\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.7762 - val_loss: 180.8072\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.2392 - val_loss: 178.0483\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3688 - val_loss: 182.4347\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.1702 - val_loss: 196.8425\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.0988 - val_loss: 184.4527\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3657 - val_loss: 182.5561\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.1559 - val_loss: 187.2349\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.0541 - val_loss: 190.6762\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3763 - val_loss: 183.3566\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.3913 - val_loss: 180.2655\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 29.4913 - val_loss: 180.2446\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.5010 - val_loss: 185.6091\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3268 - val_loss: 188.2765\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.4269 - val_loss: 190.9904\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.1230 - val_loss: 178.6724\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3640 - val_loss: 210.3093\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.5276 - val_loss: 185.8580\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3545 - val_loss: 183.8882\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.9955 - val_loss: 192.3008\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.3209 - val_loss: 205.4255\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.2300 - val_loss: 169.8273\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.3091 - val_loss: 199.6870\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.2960 - val_loss: 194.3336\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.0517 - val_loss: 192.0445\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.0123 - val_loss: 193.4561\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.2635 - val_loss: 203.4548\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.2927 - val_loss: 194.0100\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.0053 - val_loss: 187.0557\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.2032 - val_loss: 188.4879\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.8318 - val_loss: 190.5914\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.9501 - val_loss: 187.2145\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.4255 - val_loss: 206.2458\n",
      "33/33 [==============================] - 0s 902us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 28.9982 - val_loss: 183.5816\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.7278 - val_loss: 191.7096\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.7387 - val_loss: 185.4557\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.8549 - val_loss: 199.3979\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.9807 - val_loss: 184.9992\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.0995 - val_loss: 195.3968\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.0497 - val_loss: 198.0273\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.8463 - val_loss: 181.9300\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.7805 - val_loss: 196.3466\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.8951 - val_loss: 183.1682\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.0360 - val_loss: 194.7609\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.9116 - val_loss: 203.3453\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.7972 - val_loss: 192.6782\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5827 - val_loss: 193.2218\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.5969 - val_loss: 192.2825\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.6885 - val_loss: 193.0491\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.6694 - val_loss: 203.1325\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.8455 - val_loss: 182.6052\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.9685 - val_loss: 187.8903\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.0282 - val_loss: 192.1360\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5722 - val_loss: 192.1348\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.6555 - val_loss: 198.4427\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.6427 - val_loss: 192.4771\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5559 - val_loss: 194.5922\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.6263 - val_loss: 199.3150\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.0666 - val_loss: 186.0662\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.7770 - val_loss: 189.7962\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.8200 - val_loss: 194.8114\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5674 - val_loss: 195.4664\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.3344 - val_loss: 204.9273\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29.1103 - val_loss: 197.1205\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.3613 - val_loss: 193.5827\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.5107 - val_loss: 197.8665\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.4525 - val_loss: 188.6933\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.5245 - val_loss: 197.5576\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.4011 - val_loss: 193.5504\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5040 - val_loss: 200.1141\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.7356 - val_loss: 192.2375\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5951 - val_loss: 192.6059\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.6120 - val_loss: 194.0249\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.2556 - val_loss: 198.7386\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.4335 - val_loss: 189.2777\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.3252 - val_loss: 213.8005\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.9387 - val_loss: 186.6963\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.9770 - val_loss: 200.3393\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.3629 - val_loss: 193.1830\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.8736 - val_loss: 191.5811\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.4259 - val_loss: 185.1887\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.3938 - val_loss: 186.0013\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.5473 - val_loss: 209.1606\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 28.2937 - val_loss: 198.4970\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.1400 - val_loss: 192.7709\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5045 - val_loss: 190.9030\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.1144 - val_loss: 189.2097\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.5784 - val_loss: 206.7807\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.9451 - val_loss: 181.5991\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.8449 - val_loss: 199.1218\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.3093 - val_loss: 190.7937\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.7000 - val_loss: 196.8525\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.1410 - val_loss: 196.7956\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.0632 - val_loss: 188.8374\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.1786 - val_loss: 186.7639\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.1151 - val_loss: 185.3098\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.0097 - val_loss: 207.5336\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.1347 - val_loss: 190.1246\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.0675 - val_loss: 196.9022\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.0189 - val_loss: 180.6407\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.2459 - val_loss: 200.1339\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.9073 - val_loss: 192.7280\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.8310 - val_loss: 191.3242\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.0187 - val_loss: 201.9078\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.9851 - val_loss: 195.8265\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.6164 - val_loss: 187.2031\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.1911 - val_loss: 195.9012\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 28.2950 - val_loss: 204.2795\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.8446 - val_loss: 187.3656\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.1001 - val_loss: 202.7469\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.9500 - val_loss: 203.7916\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.1851 - val_loss: 188.5299\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.0637 - val_loss: 185.4203\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.9399 - val_loss: 198.0152\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.6496 - val_loss: 186.9331\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.7518 - val_loss: 195.0896\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.6217 - val_loss: 187.7941\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.9081 - val_loss: 182.3937\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.6897 - val_loss: 212.8313\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.4457 - val_loss: 187.7292\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.9771 - val_loss: 201.7749\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7070 - val_loss: 191.1483\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.8041 - val_loss: 204.4072\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5179 - val_loss: 190.1106\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7867 - val_loss: 187.1574\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.8996 - val_loss: 178.5806\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.8513 - val_loss: 194.4679\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.0778 - val_loss: 203.0435\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.6503 - val_loss: 198.3358\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7814 - val_loss: 183.0723\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.8155 - val_loss: 189.2166\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.9750 - val_loss: 198.6730\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7045 - val_loss: 182.0317\n",
      "33/33 [==============================] - 0s 979us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 27.5502 - val_loss: 199.0462\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.0644 - val_loss: 185.6971\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.7013 - val_loss: 185.3226\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.4671 - val_loss: 203.3796\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7430 - val_loss: 187.6844\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.2017 - val_loss: 193.9597\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.1737 - val_loss: 210.2866\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.7320 - val_loss: 190.8954\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5275 - val_loss: 187.9473\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5578 - val_loss: 192.3490\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.5579 - val_loss: 198.9605\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5992 - val_loss: 194.9079\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.4693 - val_loss: 198.4022\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7756 - val_loss: 199.9042\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.7922 - val_loss: 197.5105\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.3751 - val_loss: 185.5172\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 27.5421 - val_loss: 200.5653\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5700 - val_loss: 198.9070\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.7927 - val_loss: 199.5171\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5676 - val_loss: 185.4856\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.8288 - val_loss: 178.5168\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5280 - val_loss: 193.8787\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.6418 - val_loss: 189.6459\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.2240 - val_loss: 203.4238\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.6429 - val_loss: 196.0345\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.4594 - val_loss: 196.7059\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.3958 - val_loss: 187.8028\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2878 - val_loss: 207.4058\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.6603 - val_loss: 194.8200\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5120 - val_loss: 192.9187\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.8003 - val_loss: 198.8613\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2636 - val_loss: 204.0103\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7875 - val_loss: 193.1569\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5559 - val_loss: 180.0430\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.8611 - val_loss: 197.3588\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.3726 - val_loss: 198.3961\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 27.4570 - val_loss: 193.7309\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.3073 - val_loss: 203.8012\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.7469 - val_loss: 195.4837\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.4767 - val_loss: 196.6574\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.4779 - val_loss: 187.4081\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.9156 - val_loss: 197.3613\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1965 - val_loss: 197.3283\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.2343 - val_loss: 197.4983\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2625 - val_loss: 189.4777\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1561 - val_loss: 185.7584\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2340 - val_loss: 197.6833\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.3620 - val_loss: 183.7039\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.3081 - val_loss: 197.4592\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.3747 - val_loss: 192.8216\n",
      "33/33 [==============================] - 0s 936us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 27.2019 - val_loss: 197.3297\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.1557 - val_loss: 202.3409\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.0316 - val_loss: 187.0491\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.7912 - val_loss: 187.8271\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5942 - val_loss: 217.4739\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2984 - val_loss: 197.5006\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0669 - val_loss: 187.4225\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.0571 - val_loss: 199.5326\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2701 - val_loss: 201.2381\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1870 - val_loss: 193.3170\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2375 - val_loss: 190.8007\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0153 - val_loss: 198.8868\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.0427 - val_loss: 182.4934\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0121 - val_loss: 198.4854\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.0170 - val_loss: 188.2950\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1774 - val_loss: 190.6235\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.1365 - val_loss: 188.3100\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2043 - val_loss: 193.0894\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0616 - val_loss: 193.0230\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1080 - val_loss: 209.1198\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.9371 - val_loss: 192.6818\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2282 - val_loss: 184.4105\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.2054 - val_loss: 195.1625\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.5569 - val_loss: 199.1971\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1664 - val_loss: 194.2222\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1370 - val_loss: 194.6971\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.8741 - val_loss: 187.7835\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.8328 - val_loss: 202.1039\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0503 - val_loss: 190.4337\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.1909 - val_loss: 206.0724\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 27.1996 - val_loss: 198.3065\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.8908 - val_loss: 192.4868\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.8731 - val_loss: 202.9745\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.7889 - val_loss: 186.2504\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.9943 - val_loss: 203.5412\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.9728 - val_loss: 188.7947\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.8538 - val_loss: 197.5137\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.9890 - val_loss: 200.5518\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0086 - val_loss: 187.9369\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.4613 - val_loss: 184.8867\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.2213 - val_loss: 194.2156\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0520 - val_loss: 192.2487\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.8078 - val_loss: 191.5449\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.2456 - val_loss: 202.6826\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.0041 - val_loss: 189.5770\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.1931 - val_loss: 193.9403\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.3204 - val_loss: 175.1206\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.4457 - val_loss: 185.8507\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27.6082 - val_loss: 203.5720\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.9104 - val_loss: 201.8283\n",
      "33/33 [==============================] - 0s 913us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 26.7810 - val_loss: 195.1945\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.7755 - val_loss: 210.7709\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.8810 - val_loss: 201.0052\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.9705 - val_loss: 185.2714\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.7834 - val_loss: 185.4512\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.8778 - val_loss: 195.4520\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6262 - val_loss: 198.4354\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.9832 - val_loss: 190.5041\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.6242 - val_loss: 188.1009\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5967 - val_loss: 199.5380\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.7124 - val_loss: 198.9077\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.5596 - val_loss: 191.7090\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.7773 - val_loss: 194.9021\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.8090 - val_loss: 189.5009\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.8079 - val_loss: 198.1039\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5452 - val_loss: 199.9724\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6742 - val_loss: 180.9605\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.7925 - val_loss: 215.7445\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6481 - val_loss: 191.1186\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5672 - val_loss: 194.9330\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.7543 - val_loss: 196.0171\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6222 - val_loss: 213.3484\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.5955 - val_loss: 194.3307\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5844 - val_loss: 191.9783\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.7233 - val_loss: 186.6956\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0561 - val_loss: 186.9851\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.8644 - val_loss: 207.2247\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5339 - val_loss: 195.9400\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6543 - val_loss: 195.0665\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.9304 - val_loss: 199.8669\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.9517 - val_loss: 184.7183\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.9944 - val_loss: 199.8785\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.7080 - val_loss: 207.2701\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4312 - val_loss: 189.7924\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 26.8688 - val_loss: 188.2849\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.6902 - val_loss: 196.4209\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.8432 - val_loss: 208.0154\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2853 - val_loss: 193.6846\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6091 - val_loss: 191.9945\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.7291 - val_loss: 196.0821\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.6361 - val_loss: 206.2784\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3088 - val_loss: 191.9238\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5189 - val_loss: 195.0449\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.4013 - val_loss: 202.1838\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3152 - val_loss: 190.7743\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5105 - val_loss: 190.4481\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.4234 - val_loss: 200.1245\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4592 - val_loss: 188.8612\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4319 - val_loss: 202.4315\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3647 - val_loss: 206.1618\n",
      "33/33 [==============================] - 0s 921us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 26.3937 - val_loss: 180.6472\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 26.9773 - val_loss: 199.3759\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.5543 - val_loss: 202.9519\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6660 - val_loss: 208.8209\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4013 - val_loss: 186.5770\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5336 - val_loss: 197.4521\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2697 - val_loss: 202.8830\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.9715 - val_loss: 200.1997\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4372 - val_loss: 196.3031\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2898 - val_loss: 194.4206\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2607 - val_loss: 200.5047\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2231 - val_loss: 194.5798\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5014 - val_loss: 197.8372\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2868 - val_loss: 182.7730\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 27.0984 - val_loss: 190.0607\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3156 - val_loss: 201.4422\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.3141 - val_loss: 208.1258\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.5838 - val_loss: 204.7505\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3088 - val_loss: 200.5431\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4153 - val_loss: 204.0504\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.5462 - val_loss: 203.2807\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2965 - val_loss: 193.4508\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.1600 - val_loss: 201.8769\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3580 - val_loss: 208.3610\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3516 - val_loss: 203.9149\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.0338 - val_loss: 194.6914\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3634 - val_loss: 205.7785\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4150 - val_loss: 209.2021\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.6297 - val_loss: 190.0667\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1061 - val_loss: 191.6966\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4429 - val_loss: 216.1267\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 26.3347 - val_loss: 197.8258\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.3689 - val_loss: 190.4051\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.0858 - val_loss: 204.5985\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2410 - val_loss: 201.6733\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2957 - val_loss: 196.4610\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2557 - val_loss: 202.9047\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.0818 - val_loss: 201.2374\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1436 - val_loss: 206.8957\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.3162 - val_loss: 196.3341\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1987 - val_loss: 196.6740\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3594 - val_loss: 211.8615\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.0750 - val_loss: 201.7326\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1174 - val_loss: 206.6524\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.9504 - val_loss: 196.2168\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.0498 - val_loss: 189.7592\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.3626 - val_loss: 212.2891\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.9908 - val_loss: 200.2247\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.9816 - val_loss: 195.3136\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2081 - val_loss: 196.6431\n",
      "33/33 [==============================] - 0s 916us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 25.9991 - val_loss: 196.4975\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.1528 - val_loss: 202.6136\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.8624 - val_loss: 201.7520\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1721 - val_loss: 208.8516\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.9962 - val_loss: 208.0044\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1480 - val_loss: 209.6278\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1353 - val_loss: 210.5368\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.1545 - val_loss: 199.7407\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.1422 - val_loss: 228.6026\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.4973 - val_loss: 187.1468\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.8962 - val_loss: 209.8996\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.8969 - val_loss: 203.2891\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.0636 - val_loss: 191.3424\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.4966 - val_loss: 191.5238\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.9889 - val_loss: 201.6471\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.1720 - val_loss: 185.0244\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.6067 - val_loss: 196.5559\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.3252 - val_loss: 204.7892\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.7961 - val_loss: 190.1521\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.3016 - val_loss: 201.4330\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.9463 - val_loss: 199.6846\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7561 - val_loss: 201.3015\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.6965 - val_loss: 203.3486\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.9797 - val_loss: 183.4837\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.2696 - val_loss: 190.8427\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.7516 - val_loss: 203.5551\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.8448 - val_loss: 191.0779\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7518 - val_loss: 197.7010\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7281 - val_loss: 198.3184\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.7178 - val_loss: 205.2674\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.9201 - val_loss: 201.6517\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.8517 - val_loss: 204.7882\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2381 - val_loss: 195.2695\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7827 - val_loss: 202.2922\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.6863 - val_loss: 198.0945\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 25.9512 - val_loss: 209.4200\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7504 - val_loss: 193.6221\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7977 - val_loss: 190.4099\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6016 - val_loss: 192.7000\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7194 - val_loss: 195.8011\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.4598 - val_loss: 198.1390\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.8995 - val_loss: 217.0553\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.8414 - val_loss: 209.9515\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.5911 - val_loss: 202.3507\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.5690 - val_loss: 216.6499\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.8869 - val_loss: 182.9341\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2045 - val_loss: 181.1923\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.8761 - val_loss: 205.1439\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2518 - val_loss: 217.0986\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7997 - val_loss: 205.7172\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 25.4033 - val_loss: 185.1091\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.5264 - val_loss: 195.2299\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.1080 - val_loss: 214.5750\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6757 - val_loss: 211.7944\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6988 - val_loss: 200.6783\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.5977 - val_loss: 193.0109\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7761 - val_loss: 183.9555\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.0865 - val_loss: 189.9326\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 26.0028 - val_loss: 208.8678\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7805 - val_loss: 215.8552\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.8480 - val_loss: 203.7397\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.5776 - val_loss: 192.8444\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.6681 - val_loss: 203.7713\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.6386 - val_loss: 197.2041\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 25.4728 - val_loss: 200.9329\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.4195 - val_loss: 204.8055\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.5485 - val_loss: 203.8944\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.4899 - val_loss: 193.6485\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.4922 - val_loss: 197.2337\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.3528 - val_loss: 202.1070\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6171 - val_loss: 201.2339\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.5733 - val_loss: 185.0424\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.8412 - val_loss: 194.9775\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.4729 - val_loss: 210.1529\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.0374 - val_loss: 209.8185\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.5206 - val_loss: 200.8163\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.8740 - val_loss: 200.8032\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.5555 - val_loss: 193.6542\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.5488 - val_loss: 199.5070\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 25.5047 - val_loss: 204.2675\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3761 - val_loss: 217.4721\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.6824 - val_loss: 192.8268\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6280 - val_loss: 196.1832\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.4665 - val_loss: 211.9736\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.4166 - val_loss: 204.5735\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.7102 - val_loss: 185.1354\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.4058 - val_loss: 197.7034\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.2833 - val_loss: 188.1354\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3928 - val_loss: 186.0490\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3528 - val_loss: 204.0904\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6022 - val_loss: 212.7219\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.6334 - val_loss: 189.3068\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3923 - val_loss: 192.7212\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.4717 - val_loss: 209.4696\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3331 - val_loss: 200.6496\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.2110 - val_loss: 199.7593\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.4651 - val_loss: 214.9251\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.7465 - val_loss: 200.3487\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.2245 - val_loss: 206.5966\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.1502 - val_loss: 198.0454\n",
      "33/33 [==============================] - 0s 939us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 25.2728 - val_loss: 194.1893\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.1867 - val_loss: 203.6124\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0365 - val_loss: 192.5673\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.3349 - val_loss: 198.1870\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.1804 - val_loss: 194.0340\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.3344 - val_loss: 201.4679\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.6779 - val_loss: 203.3218\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.2607 - val_loss: 188.5882\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.2290 - val_loss: 203.6459\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.2091 - val_loss: 205.1956\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0356 - val_loss: 196.3241\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 25.2304 - val_loss: 190.7333\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6900 - val_loss: 176.1839\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6169 - val_loss: 203.6909\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.5733 - val_loss: 178.5762\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0651 - val_loss: 211.5074\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.2733 - val_loss: 200.6751\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.2601 - val_loss: 174.7229\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.6327 - val_loss: 194.1220\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.3948 - val_loss: 202.3898\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.4558 - val_loss: 213.0240\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.7916 - val_loss: 189.7367\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.1897 - val_loss: 202.1180\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.2647 - val_loss: 203.1626\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3740 - val_loss: 195.2573\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0967 - val_loss: 201.4494\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.8642 - val_loss: 206.1309\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.2559 - val_loss: 199.8193\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 25.3014 - val_loss: 205.0475\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3671 - val_loss: 200.5877\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0195 - val_loss: 196.3293\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0799 - val_loss: 195.2041\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.1627 - val_loss: 199.9490\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.9155 - val_loss: 212.0124\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.1116 - val_loss: 194.6249\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0053 - val_loss: 197.1014\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.1261 - val_loss: 197.0861\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0119 - val_loss: 196.6203\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.9683 - val_loss: 201.4132\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.8430 - val_loss: 209.0997\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3958 - val_loss: 196.3976\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0569 - val_loss: 193.0393\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0673 - val_loss: 194.5536\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.1871 - val_loss: 199.0280\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.3594 - val_loss: 206.9328\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.9768 - val_loss: 213.1927\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0362 - val_loss: 205.7614\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.8614 - val_loss: 205.0687\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0761 - val_loss: 196.0808\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.1027 - val_loss: 207.4992\n",
      "33/33 [==============================] - 0s 945us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.8297 - val_loss: 204.8792\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.8485 - val_loss: 203.8575\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.7041 - val_loss: 202.6982\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6482 - val_loss: 191.4006\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.6717 - val_loss: 203.7888\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.6345 - val_loss: 194.4479\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.5189 - val_loss: 209.8304\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.9048 - val_loss: 201.2418\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7313 - val_loss: 191.0043\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.1986 - val_loss: 199.3474\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7680 - val_loss: 191.0887\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.6760 - val_loss: 216.3427\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.0280 - val_loss: 193.6651\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5659 - val_loss: 205.5167\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7541 - val_loss: 197.3736\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.5577 - val_loss: 206.4054\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5676 - val_loss: 211.0876\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.9525 - val_loss: 204.5425\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.9445 - val_loss: 214.2296\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6434 - val_loss: 195.7932\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5624 - val_loss: 208.2655\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.8085 - val_loss: 207.3795\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6867 - val_loss: 202.8760\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.7431 - val_loss: 200.8361\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7430 - val_loss: 207.8269\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0825 - val_loss: 202.3429\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.5796 - val_loss: 188.0168\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.8605 - val_loss: 203.3945\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.8568 - val_loss: 225.1227\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.1452 - val_loss: 194.8189\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.5770 - val_loss: 201.8884\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.3733 - val_loss: 185.7020\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.6176 - val_loss: 209.9985\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7315 - val_loss: 203.0240\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7213 - val_loss: 195.9496\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.9252 - val_loss: 196.3459\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0503 - val_loss: 196.1949\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.4989 - val_loss: 200.5550\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5514 - val_loss: 214.3792\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.1687 - val_loss: 185.8749\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.4530 - val_loss: 192.0698\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7054 - val_loss: 183.3441\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.2393 - val_loss: 192.6036\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.3782 - val_loss: 208.7714\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6895 - val_loss: 206.1838\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.5776 - val_loss: 189.2856\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.5131 - val_loss: 202.4665\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5821 - val_loss: 207.3208\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 25.0086 - val_loss: 210.2450\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.9829 - val_loss: 185.2657\n",
      "33/33 [==============================] - 0s 907us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.4039 - val_loss: 193.1928\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.3815 - val_loss: 204.1330\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6091 - val_loss: 210.7441\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.9380 - val_loss: 197.6779\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 25.2293 - val_loss: 207.0851\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5620 - val_loss: 196.5524\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.4773 - val_loss: 185.5477\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.6594 - val_loss: 195.7933\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2839 - val_loss: 205.9474\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.3753 - val_loss: 196.9279\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.4406 - val_loss: 192.7118\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5475 - val_loss: 182.9119\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5134 - val_loss: 204.1246\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.4415 - val_loss: 205.4921\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2282 - val_loss: 198.9351\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2933 - val_loss: 200.3164\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.4023 - val_loss: 184.9386\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.7867 - val_loss: 182.9384\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.5431 - val_loss: 205.3439\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.5755 - val_loss: 189.8735\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6174 - val_loss: 187.7621\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2628 - val_loss: 189.8305\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.4679 - val_loss: 193.5750\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6873 - val_loss: 188.9840\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.3977 - val_loss: 187.5350\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1845 - val_loss: 203.3281\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6895 - val_loss: 187.6957\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.5729 - val_loss: 193.2478\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1049 - val_loss: 199.1773\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.4212 - val_loss: 201.7337\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.1571 - val_loss: 197.9004\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2027 - val_loss: 192.5341\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2591 - val_loss: 203.5696\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2988 - val_loss: 197.5891\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2370 - val_loss: 199.7585\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1749 - val_loss: 183.2452\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2685 - val_loss: 196.0146\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.0744 - val_loss: 194.8544\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1350 - val_loss: 186.2197\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.4085 - val_loss: 194.5612\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.1736 - val_loss: 195.6356\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1638 - val_loss: 187.8979\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.1853 - val_loss: 189.7205\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.0711 - val_loss: 200.0260\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.0638 - val_loss: 205.0349\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.0140 - val_loss: 188.2716\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6762 - val_loss: 196.0494\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1044 - val_loss: 206.6746\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.3728 - val_loss: 180.4935\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1541 - val_loss: 193.1642\n",
      "33/33 [==============================] - 0s 885us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.0554 - val_loss: 187.3320\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1317 - val_loss: 205.6158\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.9858 - val_loss: 202.4031\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.9705 - val_loss: 189.1570\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.9675 - val_loss: 190.4407\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.9509 - val_loss: 198.6446\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.9175 - val_loss: 197.5503\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1966 - val_loss: 191.4935\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2071 - val_loss: 200.1391\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.3886 - val_loss: 213.1471\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6532 - val_loss: 192.6586\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2459 - val_loss: 200.0865\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.9279 - val_loss: 195.6075\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.7563 - val_loss: 174.8897\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.9758 - val_loss: 197.5331\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.9090 - val_loss: 192.6145\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.8990 - val_loss: 199.2195\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.8856 - val_loss: 201.1194\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.1652 - val_loss: 198.4639\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.8699 - val_loss: 198.7191\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.9481 - val_loss: 193.6362\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8876 - val_loss: 187.7663\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.0495 - val_loss: 200.6053\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7836 - val_loss: 201.4037\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.9741 - val_loss: 186.8966\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.0431 - val_loss: 212.4038\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.3527 - val_loss: 197.4843\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8588 - val_loss: 196.2690\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.0456 - val_loss: 187.5724\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7224 - val_loss: 186.7241\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7923 - val_loss: 192.7099\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.8572 - val_loss: 199.4778\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.6390 - val_loss: 207.3678\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.9960 - val_loss: 189.3096\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7797 - val_loss: 192.7727\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.8995 - val_loss: 189.2995\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.6706 - val_loss: 191.9891\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.1378 - val_loss: 192.8325\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7747 - val_loss: 174.4470\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.4895 - val_loss: 188.0852\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.0398 - val_loss: 193.9288\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7830 - val_loss: 208.5354\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.7517 - val_loss: 188.3601\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.2530 - val_loss: 195.6798\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7375 - val_loss: 187.4218\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7307 - val_loss: 194.5149\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7498 - val_loss: 188.4510\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6697 - val_loss: 196.0400\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5299 - val_loss: 183.8232\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7309 - val_loss: 195.9673\n",
      "33/33 [==============================] - 0s 941us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.6506 - val_loss: 196.3101\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4048 - val_loss: 180.5805\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8974 - val_loss: 205.0309\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.9093 - val_loss: 200.8935\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8900 - val_loss: 199.6802\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7362 - val_loss: 190.5252\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8898 - val_loss: 192.4124\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5160 - val_loss: 192.6529\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5495 - val_loss: 192.8438\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6615 - val_loss: 199.9767\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6445 - val_loss: 175.9017\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7269 - val_loss: 195.0723\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6526 - val_loss: 207.0552\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7402 - val_loss: 190.3546\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5073 - val_loss: 191.3990\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.8493 - val_loss: 203.7196\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5714 - val_loss: 196.1143\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7424 - val_loss: 186.9805\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5371 - val_loss: 190.1659\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7697 - val_loss: 207.2079\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.9793 - val_loss: 181.3378\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.3391 - val_loss: 184.3797\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8985 - val_loss: 194.8472\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5919 - val_loss: 186.6968\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.9011 - val_loss: 193.5844\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6053 - val_loss: 194.6274\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6970 - val_loss: 200.0583\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4675 - val_loss: 185.1889\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4803 - val_loss: 196.9241\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.6368 - val_loss: 187.7740\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5221 - val_loss: 184.6754\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4272 - val_loss: 193.3473\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.6554 - val_loss: 187.2430\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5732 - val_loss: 194.5541\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7090 - val_loss: 209.2162\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7084 - val_loss: 199.7849\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4563 - val_loss: 188.4680\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5373 - val_loss: 190.5795\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8164 - val_loss: 217.1895\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6148 - val_loss: 188.4939\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.2564 - val_loss: 193.9580\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7611 - val_loss: 195.3217\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7655 - val_loss: 202.4051\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6147 - val_loss: 187.5355\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5030 - val_loss: 184.4875\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4409 - val_loss: 183.5387\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8387 - val_loss: 188.0721\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5130 - val_loss: 189.4249\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5077 - val_loss: 197.3072\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4155 - val_loss: 194.9707\n",
      "33/33 [==============================] - 0s 890us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.5695 - val_loss: 184.9515\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4752 - val_loss: 190.2226\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.2630 - val_loss: 190.6072\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3940 - val_loss: 186.6302\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3632 - val_loss: 201.6427\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4482 - val_loss: 180.5408\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7876 - val_loss: 180.2613\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.7258 - val_loss: 185.3736\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.3884 - val_loss: 185.0600\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4641 - val_loss: 183.6104\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4557 - val_loss: 195.1184\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3660 - val_loss: 193.1414\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3268 - val_loss: 196.8477\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5220 - val_loss: 202.6864\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8348 - val_loss: 178.8984\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5768 - val_loss: 176.9553\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24.0149 - val_loss: 192.2915\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4396 - val_loss: 186.9850\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4168 - val_loss: 194.4519\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5315 - val_loss: 204.5104\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4422 - val_loss: 190.0065\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.1525 - val_loss: 195.9036\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.1632 - val_loss: 188.7223\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2884 - val_loss: 180.6347\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2792 - val_loss: 202.3005\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2142 - val_loss: 184.7023\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4583 - val_loss: 178.3089\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0695 - val_loss: 197.5052\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.6939 - val_loss: 193.7994\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4249 - val_loss: 189.6939\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4409 - val_loss: 195.7640\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.4454 - val_loss: 180.9062\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3428 - val_loss: 186.9372\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2274 - val_loss: 205.1204\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3687 - val_loss: 188.1459\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5279 - val_loss: 181.8569\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.7356 - val_loss: 188.1167\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2171 - val_loss: 190.6320\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.6210 - val_loss: 191.9084\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3875 - val_loss: 182.4129\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5595 - val_loss: 185.7100\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.2111 - val_loss: 172.3000\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.7631 - val_loss: 175.9650\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4414 - val_loss: 187.4745\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0607 - val_loss: 184.0510\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0836 - val_loss: 196.1969\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4648 - val_loss: 181.8672\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4053 - val_loss: 177.9084\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.3797 - val_loss: 188.7744\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.1623 - val_loss: 183.3949\n",
      "33/33 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.0835 - val_loss: 187.1774\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1524 - val_loss: 194.6415\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.2160 - val_loss: 179.3220\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.2012 - val_loss: 174.8859\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5961 - val_loss: 188.0851\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2423 - val_loss: 185.1180\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0692 - val_loss: 196.1837\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2867 - val_loss: 187.1026\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.3627 - val_loss: 180.1909\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4286 - val_loss: 191.9165\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1370 - val_loss: 186.9431\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.2891 - val_loss: 213.0444\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.6439 - val_loss: 209.7425\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.4512 - val_loss: 199.7204\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9791 - val_loss: 185.4801\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0000 - val_loss: 197.0181\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1963 - val_loss: 196.5432\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1641 - val_loss: 194.7529\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2710 - val_loss: 189.2239\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0048 - val_loss: 193.5429\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.2316 - val_loss: 201.5825\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5226 - val_loss: 187.4262\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9639 - val_loss: 179.4747\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4365 - val_loss: 170.4771\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.4396 - val_loss: 181.5679\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.9351 - val_loss: 180.3017\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0079 - val_loss: 173.3226\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.3328 - val_loss: 200.5233\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2849 - val_loss: 198.0476\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.3467 - val_loss: 184.1268\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0063 - val_loss: 169.1437\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.5338 - val_loss: 179.3446\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.4548 - val_loss: 176.5824\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1937 - val_loss: 177.9843\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.9836 - val_loss: 174.1190\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.5841 - val_loss: 177.8908\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.3425 - val_loss: 193.5724\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9178 - val_loss: 174.6655\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7934 - val_loss: 198.3835\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.2524 - val_loss: 194.3157\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.3579 - val_loss: 193.1359\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0902 - val_loss: 190.2651\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9882 - val_loss: 179.0078\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2017 - val_loss: 172.9239\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.6277 - val_loss: 183.9003\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2208 - val_loss: 208.2745\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.1473 - val_loss: 196.6900\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9455 - val_loss: 187.6740\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9824 - val_loss: 171.9570\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.6777 - val_loss: 183.7281\n",
      "33/33 [==============================] - 0s 887us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.9644 - val_loss: 181.6336\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1166 - val_loss: 186.2066\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1404 - val_loss: 192.3509\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.8083 - val_loss: 198.3755\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.7725 - val_loss: 180.3556\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9500 - val_loss: 203.2139\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.3182 - val_loss: 184.0818\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9547 - val_loss: 197.9701\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0040 - val_loss: 192.0155\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7787 - val_loss: 170.7288\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0821 - val_loss: 188.0721\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8969 - val_loss: 202.1289\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0285 - val_loss: 189.8827\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.3490 - val_loss: 194.6419\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8364 - val_loss: 174.4272\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0433 - val_loss: 194.8665\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7139 - val_loss: 175.6172\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8308 - val_loss: 189.3915\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8316 - val_loss: 199.6414\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9653 - val_loss: 184.2747\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0705 - val_loss: 183.8802\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.8645 - val_loss: 192.7269\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7774 - val_loss: 184.4051\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6659 - val_loss: 188.3147\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.6957 - val_loss: 187.8125\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.9212 - val_loss: 185.4173\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7212 - val_loss: 187.9641\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9261 - val_loss: 192.1157\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.7897 - val_loss: 193.6521\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7273 - val_loss: 194.3782\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.7016 - val_loss: 186.5877\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.7002 - val_loss: 192.4387\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5705 - val_loss: 186.5009\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5279 - val_loss: 186.8502\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9364 - val_loss: 193.9183\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5416 - val_loss: 197.8576\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.5727 - val_loss: 186.7785\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6641 - val_loss: 189.6245\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7100 - val_loss: 184.5737\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.1351 - val_loss: 182.8795\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7427 - val_loss: 193.2947\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8930 - val_loss: 189.3457\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5549 - val_loss: 195.2790\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.8532 - val_loss: 191.2343\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8627 - val_loss: 198.3661\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7564 - val_loss: 179.3982\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0760 - val_loss: 172.8662\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6959 - val_loss: 185.2783\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5598 - val_loss: 192.5561\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.5753 - val_loss: 190.3820\n",
      "33/33 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.5195 - val_loss: 186.2063\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3402 - val_loss: 171.4766\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.2041 - val_loss: 199.3255\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7687 - val_loss: 186.4004\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7060 - val_loss: 184.2111\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.6874 - val_loss: 176.7541\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7803 - val_loss: 179.0757\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9979 - val_loss: 205.1139\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8009 - val_loss: 195.3648\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5192 - val_loss: 184.6158\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5946 - val_loss: 175.8416\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7986 - val_loss: 192.8713\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4552 - val_loss: 187.2440\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4176 - val_loss: 195.2418\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4127 - val_loss: 182.5430\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7017 - val_loss: 182.7580\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4824 - val_loss: 182.5716\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5798 - val_loss: 176.8314\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3608 - val_loss: 185.5884\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.7162 - val_loss: 176.2637\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5815 - val_loss: 186.4387\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5822 - val_loss: 183.8908\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4833 - val_loss: 191.2773\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.6770 - val_loss: 192.3424\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5360 - val_loss: 177.2404\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6923 - val_loss: 179.4507\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.6524 - val_loss: 182.7116\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5659 - val_loss: 185.8400\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4617 - val_loss: 190.7007\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.6682 - val_loss: 179.0061\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 23.1708 - val_loss: 193.3600\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.9779 - val_loss: 193.1671\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4372 - val_loss: 175.4888\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4900 - val_loss: 195.2860\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.8238 - val_loss: 176.8918\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4779 - val_loss: 181.5959\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4009 - val_loss: 180.4797\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7421 - val_loss: 179.0688\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3400 - val_loss: 190.7220\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4979 - val_loss: 178.9810\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6765 - val_loss: 179.2983\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6030 - val_loss: 185.8496\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.9450 - val_loss: 189.2483\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6326 - val_loss: 187.3197\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5763 - val_loss: 188.0614\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5744 - val_loss: 185.4985\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4856 - val_loss: 191.7674\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3182 - val_loss: 179.0287\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3920 - val_loss: 186.8047\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4481 - val_loss: 181.0495\n",
      "33/33 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.7703 - val_loss: 185.5185\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3527 - val_loss: 174.8348\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7618 - val_loss: 181.0364\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4360 - val_loss: 191.7952\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5241 - val_loss: 188.0870\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3864 - val_loss: 187.9042\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3606 - val_loss: 195.9395\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3242 - val_loss: 181.3377\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3959 - val_loss: 191.1001\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5779 - val_loss: 176.0055\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4383 - val_loss: 180.2886\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4202 - val_loss: 182.7579\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.2526 - val_loss: 190.2770\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3498 - val_loss: 196.0918\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5023 - val_loss: 177.3273\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7712 - val_loss: 168.2841\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.2467 - val_loss: 167.7750\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.8278 - val_loss: 176.8508\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.1265 - val_loss: 184.9310\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4119 - val_loss: 180.0653\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6358 - val_loss: 177.1198\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3771 - val_loss: 188.6364\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5154 - val_loss: 173.4599\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2001 - val_loss: 193.0681\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4345 - val_loss: 185.5531\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4722 - val_loss: 187.1933\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.1660 - val_loss: 178.8474\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3338 - val_loss: 188.6298\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1368 - val_loss: 179.3146\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2109 - val_loss: 185.1872\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2906 - val_loss: 171.1422\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.6291 - val_loss: 178.1512\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4129 - val_loss: 182.0351\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2581 - val_loss: 181.9795\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1369 - val_loss: 198.2271\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5013 - val_loss: 186.9792\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1764 - val_loss: 177.5169\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2226 - val_loss: 183.7459\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4706 - val_loss: 194.6205\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.8838 - val_loss: 190.7389\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1966 - val_loss: 182.8129\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4373 - val_loss: 175.4364\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1524 - val_loss: 180.6604\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1751 - val_loss: 177.8913\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9340 - val_loss: 193.1925\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2373 - val_loss: 184.2355\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3165 - val_loss: 180.5900\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6874 - val_loss: 176.5794\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2364 - val_loss: 167.0627\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.1243 - val_loss: 194.0490\n",
      "33/33 [==============================] - 0s 872us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.3750 - val_loss: 193.5022\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4709 - val_loss: 180.8368\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3691 - val_loss: 183.9176\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4011 - val_loss: 175.5842\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3684 - val_loss: 187.3436\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6138 - val_loss: 182.6531\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.2201 - val_loss: 181.8583\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4994 - val_loss: 181.8557\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1855 - val_loss: 170.5494\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5478 - val_loss: 171.4946\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4658 - val_loss: 180.4147\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0115 - val_loss: 181.9650\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0509 - val_loss: 181.2483\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4049 - val_loss: 179.0756\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3720 - val_loss: 178.2729\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1127 - val_loss: 180.5350\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.7294 - val_loss: 183.3306\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.0221 - val_loss: 181.3774\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9609 - val_loss: 181.4384\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4788 - val_loss: 171.2637\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3357 - val_loss: 175.1498\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1530 - val_loss: 181.9000\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.9153 - val_loss: 187.3659\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.6677 - val_loss: 191.0038\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4566 - val_loss: 182.3235\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 23.0032 - val_loss: 195.2452\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.5852 - val_loss: 173.5561\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0292 - val_loss: 184.3557\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9463 - val_loss: 185.9646\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8148 - val_loss: 170.5238\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3126 - val_loss: 189.5694\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1850 - val_loss: 182.9653\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3621 - val_loss: 178.1803\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9572 - val_loss: 182.0929\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.1647 - val_loss: 174.5750\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23.0784 - val_loss: 163.8450\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3109 - val_loss: 190.0987\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.0932 - val_loss: 201.7965\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.7256 - val_loss: 186.1496\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.0057 - val_loss: 193.3051\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2930 - val_loss: 191.3438\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.0323 - val_loss: 176.8367\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9664 - val_loss: 172.8378\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1861 - val_loss: 174.9453\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1628 - val_loss: 183.6711\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.0616 - val_loss: 198.3298\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1611 - val_loss: 191.0673\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3510 - val_loss: 183.7883\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9794 - val_loss: 194.9017\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1988 - val_loss: 196.6050\n",
      "33/33 [==============================] - 0s 904us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.5359 - val_loss: 181.8344\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0007 - val_loss: 174.0398\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1388 - val_loss: 181.3201\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0459 - val_loss: 183.4379\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1071 - val_loss: 185.0377\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7934 - val_loss: 183.2536\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1860 - val_loss: 184.8542\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8397 - val_loss: 180.7550\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.1092 - val_loss: 194.5451\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.4471 - val_loss: 194.1352\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0775 - val_loss: 193.5719\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0282 - val_loss: 176.8441\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8688 - val_loss: 192.2223\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.7489 - val_loss: 184.9494\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.3435 - val_loss: 172.1571\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 22.2663 - val_loss: 185.1642\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.5073 - val_loss: 173.4576\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8085 - val_loss: 179.9122\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0918 - val_loss: 211.5773\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1392 - val_loss: 176.7577\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.2707 - val_loss: 173.5797\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0863 - val_loss: 188.7753\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0878 - val_loss: 173.2455\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.9213 - val_loss: 187.3418\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8303 - val_loss: 174.3639\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8337 - val_loss: 183.6899\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8649 - val_loss: 173.8956\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9104 - val_loss: 186.1483\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8843 - val_loss: 185.9627\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0698 - val_loss: 171.3582\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.2021 - val_loss: 165.0181\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9854 - val_loss: 195.2748\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8517 - val_loss: 178.8807\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9244 - val_loss: 180.3620\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6933 - val_loss: 181.3628\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6824 - val_loss: 191.7088\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0049 - val_loss: 192.5945\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7622 - val_loss: 188.7459\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.0390 - val_loss: 185.5617\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8254 - val_loss: 178.6635\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8550 - val_loss: 173.6591\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3662 - val_loss: 182.7154\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.4131 - val_loss: 210.0224\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.3344 - val_loss: 199.7536\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2045 - val_loss: 195.3255\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9273 - val_loss: 192.2788\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6427 - val_loss: 186.7578\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.5553 - val_loss: 189.8106\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6098 - val_loss: 199.4850\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2531 - val_loss: 175.6955\n",
      "33/33 [==============================] - 0s 997us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.7704 - val_loss: 170.7231\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9756 - val_loss: 181.1248\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.0538 - val_loss: 185.5236\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8518 - val_loss: 199.4564\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8309 - val_loss: 178.1118\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6819 - val_loss: 191.1325\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.5732 - val_loss: 174.9999\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2709 - val_loss: 188.8639\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.7909 - val_loss: 171.8144\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.8668 - val_loss: 188.5774\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8862 - val_loss: 192.2921\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6338 - val_loss: 185.8319\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6424 - val_loss: 188.4275\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8816 - val_loss: 186.2500\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6363 - val_loss: 181.6693\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2852 - val_loss: 189.1733\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8347 - val_loss: 192.7360\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6145 - val_loss: 191.3424\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.7025 - val_loss: 171.4990\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6887 - val_loss: 185.7490\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2934 - val_loss: 190.7469\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.6636 - val_loss: 183.5356\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6561 - val_loss: 182.0228\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8612 - val_loss: 168.6076\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0679 - val_loss: 168.3948\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8299 - val_loss: 183.3629\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6895 - val_loss: 197.3888\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4980 - val_loss: 180.2930\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6152 - val_loss: 185.9651\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4989 - val_loss: 169.9233\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2954 - val_loss: 182.1423\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1182 - val_loss: 191.1918\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6364 - val_loss: 183.3098\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7935 - val_loss: 175.4839\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4723 - val_loss: 197.2755\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9491 - val_loss: 169.8698\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 22.2342 - val_loss: 177.8815\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4448 - val_loss: 172.6908\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.9028 - val_loss: 179.7653\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6841 - val_loss: 190.6539\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.5935 - val_loss: 197.4171\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7505 - val_loss: 178.1554\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4319 - val_loss: 182.2077\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.5561 - val_loss: 180.9014\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6876 - val_loss: 177.3434\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5253 - val_loss: 174.4567\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2685 - val_loss: 186.2927\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6499 - val_loss: 180.2537\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4542 - val_loss: 187.4525\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5945 - val_loss: 183.8915\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.8738 - val_loss: 189.0292\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.7653 - val_loss: 176.1626\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2691 - val_loss: 180.5743\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4693 - val_loss: 189.4708\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.8345 - val_loss: 177.6824\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6043 - val_loss: 186.7150\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.4121 - val_loss: 178.0609\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.5716 - val_loss: 180.4547\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8415 - val_loss: 184.1853\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6230 - val_loss: 183.0973\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.6587 - val_loss: 193.7101\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4820 - val_loss: 178.8837\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4203 - val_loss: 181.6020\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.5724 - val_loss: 182.0789\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4170 - val_loss: 172.3899\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3690 - val_loss: 203.0348\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5766 - val_loss: 177.0091\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3814 - val_loss: 184.5261\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2371 - val_loss: 185.5389\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3716 - val_loss: 187.9594\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.6148 - val_loss: 186.1848\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3830 - val_loss: 182.3830\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7050 - val_loss: 184.3683\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9060 - val_loss: 197.9347\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9942 - val_loss: 204.1677\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8114 - val_loss: 183.9103\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1348 - val_loss: 189.1276\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.1221 - val_loss: 176.2238\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4547 - val_loss: 169.4641\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3664 - val_loss: 185.3072\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3254 - val_loss: 182.7104\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3635 - val_loss: 179.2879\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9268 - val_loss: 182.7891\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4460 - val_loss: 187.9875\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4673 - val_loss: 177.3395\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.7185 - val_loss: 161.7591\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.9631 - val_loss: 172.0934\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3169 - val_loss: 188.3533\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5029 - val_loss: 192.5985\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.7940 - val_loss: 188.7608\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1359 - val_loss: 180.6459\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4666 - val_loss: 187.7751\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1870 - val_loss: 180.7750\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3553 - val_loss: 167.6983\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.5553 - val_loss: 184.0737\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2625 - val_loss: 180.2053\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1209 - val_loss: 180.2385\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2358 - val_loss: 185.7174\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2453 - val_loss: 185.3789\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3661 - val_loss: 175.0635\n",
      "33/33 [==============================] - 0s 836us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.2242 - val_loss: 172.3258\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4543 - val_loss: 183.4601\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5794 - val_loss: 174.2451\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2986 - val_loss: 174.3887\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3223 - val_loss: 174.9908\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2198 - val_loss: 174.9499\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.5334 - val_loss: 166.8751\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3284 - val_loss: 166.8309\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7164 - val_loss: 171.6227\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5407 - val_loss: 162.8842\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2480 - val_loss: 184.2472\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5143 - val_loss: 177.0745\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.8619 - val_loss: 189.0771\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.2117 - val_loss: 179.2202\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0653 - val_loss: 185.3275\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0808 - val_loss: 185.8330\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4962 - val_loss: 186.1586\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4067 - val_loss: 174.2314\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2060 - val_loss: 170.5894\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7485 - val_loss: 160.9780\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 22.0207 - val_loss: 166.8122\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2930 - val_loss: 171.2208\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3875 - val_loss: 174.5394\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0000 - val_loss: 183.9852\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2387 - val_loss: 174.4173\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1558 - val_loss: 169.9149\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4132 - val_loss: 172.4583\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2137 - val_loss: 172.8259\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.0025 - val_loss: 182.4176\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1045 - val_loss: 190.3958\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9889 - val_loss: 178.6010\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1444 - val_loss: 175.8560\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0873 - val_loss: 175.7406\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1418 - val_loss: 163.7695\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9304 - val_loss: 188.4148\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2010 - val_loss: 167.4508\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4290 - val_loss: 178.4642\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2351 - val_loss: 171.5071\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0893 - val_loss: 170.7264\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.7510 - val_loss: 173.1412\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1224 - val_loss: 170.4934\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0212 - val_loss: 185.8821\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0061 - val_loss: 179.2397\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0032 - val_loss: 173.1560\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3428 - val_loss: 168.3811\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5415 - val_loss: 169.6462\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.5234 - val_loss: 171.5840\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2828 - val_loss: 170.0712\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8954 - val_loss: 184.3087\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0410 - val_loss: 164.4579\n",
      "33/33 [==============================] - 0s 900us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.4607 - val_loss: 176.9044\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4142 - val_loss: 170.4482\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0642 - val_loss: 172.3905\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1317 - val_loss: 170.5492\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4704 - val_loss: 184.5463\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1814 - val_loss: 173.6720\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1134 - val_loss: 180.9533\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9795 - val_loss: 180.2313\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1604 - val_loss: 171.3417\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9588 - val_loss: 190.4023\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9204 - val_loss: 177.1079\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8334 - val_loss: 183.3259\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1495 - val_loss: 178.3806\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9588 - val_loss: 188.9611\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9905 - val_loss: 180.1545\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9357 - val_loss: 180.4872\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0170 - val_loss: 176.2814\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2297 - val_loss: 181.8536\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0606 - val_loss: 176.8596\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6128 - val_loss: 174.3466\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9961 - val_loss: 168.8214\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.0102 - val_loss: 167.5897\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8878 - val_loss: 176.1254\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8749 - val_loss: 182.6591\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0926 - val_loss: 186.9909\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4321 - val_loss: 169.0722\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2518 - val_loss: 177.7536\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1962 - val_loss: 182.7474\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9271 - val_loss: 171.3313\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1957 - val_loss: 173.7202\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.8698 - val_loss: 188.2471\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.6217 - val_loss: 191.9991\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0701 - val_loss: 177.0339\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9114 - val_loss: 184.6442\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1687 - val_loss: 165.4818\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8990 - val_loss: 170.6632\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9933 - val_loss: 179.8707\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8117 - val_loss: 179.7254\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9511 - val_loss: 189.2818\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9214 - val_loss: 173.4218\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7622 - val_loss: 173.9353\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1001 - val_loss: 180.3874\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1490 - val_loss: 190.6041\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3855 - val_loss: 186.6859\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0749 - val_loss: 174.4926\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1217 - val_loss: 183.3380\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4410 - val_loss: 178.5934\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8979 - val_loss: 188.9034\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9341 - val_loss: 171.5683\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2512 - val_loss: 180.2602\n",
      "33/33 [==============================] - 0s 935us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.0729 - val_loss: 185.7704\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1621 - val_loss: 180.1511\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.3392 - val_loss: 181.5994\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7458 - val_loss: 181.3868\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0090 - val_loss: 192.8750\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9422 - val_loss: 179.8556\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7661 - val_loss: 164.2427\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9488 - val_loss: 183.1220\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9463 - val_loss: 180.9822\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7426 - val_loss: 165.9179\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1308 - val_loss: 168.5431\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0827 - val_loss: 176.7386\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.9332 - val_loss: 179.4948\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8872 - val_loss: 179.7303\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0036 - val_loss: 183.6494\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8699 - val_loss: 176.7739\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.3031 - val_loss: 194.1749\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.4622 - val_loss: 186.5201\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2378 - val_loss: 171.5311\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7497 - val_loss: 168.2405\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8826 - val_loss: 182.1604\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5565 - val_loss: 186.7720\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4390 - val_loss: 168.3369\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9666 - val_loss: 187.2802\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2503 - val_loss: 165.9440\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1207 - val_loss: 175.5081\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6694 - val_loss: 186.3647\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9945 - val_loss: 183.2021\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1931 - val_loss: 185.1303\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0557 - val_loss: 193.5503\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8623 - val_loss: 170.4597\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7855 - val_loss: 176.7330\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8880 - val_loss: 172.9929\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8116 - val_loss: 178.2236\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9635 - val_loss: 184.6228\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9932 - val_loss: 181.3986\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6698 - val_loss: 188.6704\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1977 - val_loss: 181.5765\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.8085 - val_loss: 171.4755\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9877 - val_loss: 161.8300\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0008 - val_loss: 177.6429\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7917 - val_loss: 180.1578\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5790 - val_loss: 185.0335\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8579 - val_loss: 181.6723\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7524 - val_loss: 176.6290\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9752 - val_loss: 161.0567\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0249 - val_loss: 185.1723\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0043 - val_loss: 182.5707\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0659 - val_loss: 169.2371\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0026 - val_loss: 177.9177\n",
      "33/33 [==============================] - 0s 971us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.3025 - val_loss: 172.1355\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9250 - val_loss: 174.3991\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6727 - val_loss: 183.4422\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8537 - val_loss: 178.4485\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8336 - val_loss: 179.7511\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6855 - val_loss: 181.5777\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6507 - val_loss: 178.5395\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6882 - val_loss: 179.8205\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7368 - val_loss: 178.9944\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4551 - val_loss: 184.5883\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1029 - val_loss: 188.8065\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1527 - val_loss: 177.2542\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.6952 - val_loss: 180.5276\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0358 - val_loss: 183.4412\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8444 - val_loss: 181.5774\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0383 - val_loss: 169.8904\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9496 - val_loss: 169.8595\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5590 - val_loss: 178.0004\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7867 - val_loss: 181.3387\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6742 - val_loss: 176.5825\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0115 - val_loss: 181.7755\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7145 - val_loss: 167.9537\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9119 - val_loss: 176.2818\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9261 - val_loss: 168.6654\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0214 - val_loss: 169.7990\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8140 - val_loss: 172.2828\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9493 - val_loss: 178.9671\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7537 - val_loss: 172.2987\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5121 - val_loss: 182.2156\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6985 - val_loss: 178.2410\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9951 - val_loss: 173.6857\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.8405 - val_loss: 164.0034\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9524 - val_loss: 162.2505\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.1908 - val_loss: 167.8117\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4474 - val_loss: 186.0980\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4885 - val_loss: 180.1848\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6617 - val_loss: 173.8649\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6850 - val_loss: 189.2982\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6932 - val_loss: 173.1630\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8798 - val_loss: 178.7026\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1299 - val_loss: 187.4766\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0826 - val_loss: 185.6253\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5532 - val_loss: 161.8705\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8636 - val_loss: 178.3178\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0524 - val_loss: 169.1233\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1991 - val_loss: 167.5508\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9105 - val_loss: 175.6841\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5916 - val_loss: 186.9236\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9576 - val_loss: 174.7751\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7901 - val_loss: 179.1216\n",
      "33/33 [==============================] - 0s 910us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.4938 - val_loss: 171.7443\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8082 - val_loss: 176.9403\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7411 - val_loss: 179.6281\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5511 - val_loss: 186.7402\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9150 - val_loss: 180.1221\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4312 - val_loss: 174.2725\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9420 - val_loss: 173.2031\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7338 - val_loss: 163.2793\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5252 - val_loss: 182.6162\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8456 - val_loss: 178.5775\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8669 - val_loss: 170.0939\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6697 - val_loss: 180.4070\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6767 - val_loss: 193.9702\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3448 - val_loss: 163.5677\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1733 - val_loss: 166.0729\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9415 - val_loss: 178.4408\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7604 - val_loss: 174.0438\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.6994 - val_loss: 168.4682\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9659 - val_loss: 174.4586\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7840 - val_loss: 175.3470\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6031 - val_loss: 172.9183\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7534 - val_loss: 178.7224\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6362 - val_loss: 183.1755\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5978 - val_loss: 180.1767\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9997 - val_loss: 169.0517\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5303 - val_loss: 182.2077\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7749 - val_loss: 170.0010\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5669 - val_loss: 177.3631\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8013 - val_loss: 174.1945\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.7482 - val_loss: 175.7355\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5562 - val_loss: 178.0264\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4042 - val_loss: 175.9277\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4698 - val_loss: 175.1843\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6231 - val_loss: 160.7725\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9963 - val_loss: 176.1149\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5238 - val_loss: 188.0623\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5898 - val_loss: 183.7203\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7267 - val_loss: 158.3457\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.2032 - val_loss: 161.6046\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6943 - val_loss: 177.4761\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4947 - val_loss: 180.5656\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.3492 - val_loss: 174.7439\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4562 - val_loss: 183.9729\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6479 - val_loss: 175.4290\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5230 - val_loss: 180.9429\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3625 - val_loss: 167.2370\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5749 - val_loss: 175.8533\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5898 - val_loss: 171.2488\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5940 - val_loss: 178.5068\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7753 - val_loss: 177.9222\n",
      "33/33 [==============================] - 0s 842us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.8445 - val_loss: 170.7014\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5617 - val_loss: 172.1987\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.8673 - val_loss: 183.5087\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5610 - val_loss: 168.9907\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6794 - val_loss: 169.8177\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4041 - val_loss: 182.4436\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8749 - val_loss: 184.0153\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7171 - val_loss: 181.9782\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.1733 - val_loss: 170.7187\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4879 - val_loss: 165.6974\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5099 - val_loss: 169.6145\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9417 - val_loss: 169.0792\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.4260 - val_loss: 179.4130\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.5193 - val_loss: 197.3874\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.0630 - val_loss: 181.0153\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7836 - val_loss: 176.4475\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5535 - val_loss: 177.3965\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5609 - val_loss: 180.9702\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6901 - val_loss: 172.6336\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4231 - val_loss: 168.3240\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6401 - val_loss: 169.6738\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4517 - val_loss: 190.6918\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2813 - val_loss: 171.5719\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4555 - val_loss: 179.2135\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8169 - val_loss: 173.4041\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5498 - val_loss: 165.0852\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6335 - val_loss: 174.6170\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4027 - val_loss: 175.2610\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3148 - val_loss: 185.9821\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.3531 - val_loss: 174.8558\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5156 - val_loss: 161.7584\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.2928 - val_loss: 160.6597\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9311 - val_loss: 170.7989\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5569 - val_loss: 182.7030\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8026 - val_loss: 172.9157\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3399 - val_loss: 168.3389\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7183 - val_loss: 176.1105\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3840 - val_loss: 181.1549\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2429 - val_loss: 174.7250\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3487 - val_loss: 179.1158\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3303 - val_loss: 189.4188\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6414 - val_loss: 181.9728\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6084 - val_loss: 175.7776\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4588 - val_loss: 168.3758\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3415 - val_loss: 181.7853\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3335 - val_loss: 179.5227\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4085 - val_loss: 180.2679\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9644 - val_loss: 172.7649\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0194 - val_loss: 174.9502\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5729 - val_loss: 176.0676\n",
      "33/33 [==============================] - 0s 889us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.0732 - val_loss: 175.4702\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8071 - val_loss: 179.9573\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4622 - val_loss: 181.8254\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4770 - val_loss: 179.0722\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4294 - val_loss: 170.6015\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9370 - val_loss: 176.6887\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7692 - val_loss: 185.2896\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2746 - val_loss: 163.0793\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8440 - val_loss: 165.6718\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8264 - val_loss: 161.3257\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 21.0554 - val_loss: 160.9279\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3219 - val_loss: 186.2253\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7843 - val_loss: 188.4530\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7234 - val_loss: 180.6095\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4071 - val_loss: 171.8068\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3417 - val_loss: 174.9066\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5337 - val_loss: 175.4949\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6385 - val_loss: 177.5229\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.3460 - val_loss: 166.7952\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3875 - val_loss: 181.9272\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7032 - val_loss: 170.6835\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3044 - val_loss: 172.9607\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4224 - val_loss: 183.9111\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5865 - val_loss: 169.3080\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3902 - val_loss: 182.5001\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6467 - val_loss: 169.3757\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3113 - val_loss: 176.3078\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3725 - val_loss: 175.0269\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4423 - val_loss: 169.3420\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5299 - val_loss: 163.1535\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4139 - val_loss: 168.6402\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.9820 - val_loss: 169.8427\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4007 - val_loss: 178.2994\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3399 - val_loss: 169.1489\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.1668 - val_loss: 176.8711\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2201 - val_loss: 184.2634\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0565 - val_loss: 167.9971\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3568 - val_loss: 172.7899\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5112 - val_loss: 180.4925\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3799 - val_loss: 177.1141\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5104 - val_loss: 175.5342\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2634 - val_loss: 173.3188\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4348 - val_loss: 178.5358\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4054 - val_loss: 170.4008\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2772 - val_loss: 177.5666\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3281 - val_loss: 191.5353\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7078 - val_loss: 170.8631\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5975 - val_loss: 170.9586\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6359 - val_loss: 162.4290\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6226 - val_loss: 168.1340\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 21.1382 - val_loss: 166.3350\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 21.1750 - val_loss: 170.6071\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2108 - val_loss: 185.8092\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4268 - val_loss: 174.3356\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6902 - val_loss: 158.6964\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2621 - val_loss: 171.7645\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3598 - val_loss: 174.0682\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4520 - val_loss: 180.1907\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2439 - val_loss: 171.9869\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4310 - val_loss: 178.9713\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3305 - val_loss: 178.7412\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4734 - val_loss: 182.7244\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7102 - val_loss: 156.6481\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.8048 - val_loss: 158.1823\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3768 - val_loss: 169.9546\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2590 - val_loss: 176.0750\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4229 - val_loss: 172.7719\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0908 - val_loss: 172.8689\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1327 - val_loss: 178.7508\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1498 - val_loss: 170.7583\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4588 - val_loss: 174.2015\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2426 - val_loss: 170.2696\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2817 - val_loss: 163.2724\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9504 - val_loss: 162.7042\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3698 - val_loss: 172.5282\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1724 - val_loss: 170.2941\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4635 - val_loss: 168.2285\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4517 - val_loss: 170.2020\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6595 - val_loss: 168.8957\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1880 - val_loss: 175.3458\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4455 - val_loss: 168.4054\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3368 - val_loss: 169.0322\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3207 - val_loss: 171.0885\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2628 - val_loss: 171.9209\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2594 - val_loss: 168.0872\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5254 - val_loss: 178.5609\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3110 - val_loss: 167.4240\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4483 - val_loss: 171.6372\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4242 - val_loss: 169.4716\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2648 - val_loss: 158.5628\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4068 - val_loss: 169.7480\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5542 - val_loss: 164.1251\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3618 - val_loss: 172.6118\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2253 - val_loss: 177.1686\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1989 - val_loss: 188.6190\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.7177 - val_loss: 180.8902\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4437 - val_loss: 176.7867\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1451 - val_loss: 173.8857\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.1162 - val_loss: 169.2276\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1737 - val_loss: 169.8822\n",
      "33/33 [==============================] - 0s 964us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.2284 - val_loss: 174.8721\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1859 - val_loss: 159.3239\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0410 - val_loss: 167.2391\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1334 - val_loss: 161.4646\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3683 - val_loss: 191.1119\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4396 - val_loss: 186.4403\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1790 - val_loss: 174.3947\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2957 - val_loss: 172.5422\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.3935 - val_loss: 179.3624\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.8766 - val_loss: 168.2708\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3365 - val_loss: 172.4113\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6138 - val_loss: 166.5362\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3230 - val_loss: 167.9928\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1261 - val_loss: 176.2943\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2730 - val_loss: 178.6028\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3558 - val_loss: 176.1344\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7715 - val_loss: 174.6491\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2829 - val_loss: 163.5508\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0770 - val_loss: 174.7129\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1634 - val_loss: 176.3526\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1059 - val_loss: 164.2859\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2547 - val_loss: 168.0947\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.2142 - val_loss: 169.9551\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0212 - val_loss: 184.2508\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2571 - val_loss: 183.5052\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4927 - val_loss: 164.6234\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2000 - val_loss: 170.0222\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5685 - val_loss: 184.1098\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.3069 - val_loss: 183.2024\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4110 - val_loss: 189.1520\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7332 - val_loss: 192.6162\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.9012 - val_loss: 189.8499\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4637 - val_loss: 180.9532\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0287 - val_loss: 177.5335\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1675 - val_loss: 176.3724\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2489 - val_loss: 175.2929\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2336 - val_loss: 171.4641\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1970 - val_loss: 169.9331\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0489 - val_loss: 163.4014\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4197 - val_loss: 169.2114\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4166 - val_loss: 173.5267\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2263 - val_loss: 166.2665\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6677 - val_loss: 163.8917\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9627 - val_loss: 182.7567\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9701 - val_loss: 171.7065\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1640 - val_loss: 167.6557\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6259 - val_loss: 169.9583\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9771 - val_loss: 173.6565\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2316 - val_loss: 174.7104\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1893 - val_loss: 200.2792\n",
      "33/33 [==============================] - 0s 841us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 21.3075 - val_loss: 174.1446\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3204 - val_loss: 176.9706\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2280 - val_loss: 186.0685\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2486 - val_loss: 178.4869\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0359 - val_loss: 173.1538\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1700 - val_loss: 186.7539\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1033 - val_loss: 177.9532\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1321 - val_loss: 177.6799\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1582 - val_loss: 168.6378\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9841 - val_loss: 181.9224\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0445 - val_loss: 183.0609\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3213 - val_loss: 182.6661\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3769 - val_loss: 180.3245\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5149 - val_loss: 180.4469\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1987 - val_loss: 183.2470\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3186 - val_loss: 183.9436\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3472 - val_loss: 181.1860\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.9197 - val_loss: 171.4806\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9482 - val_loss: 172.6385\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1409 - val_loss: 172.8661\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0338 - val_loss: 159.6817\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4819 - val_loss: 175.8823\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0604 - val_loss: 174.3960\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0554 - val_loss: 175.0701\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3066 - val_loss: 167.7087\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2081 - val_loss: 174.0962\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1723 - val_loss: 154.8134\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6035 - val_loss: 164.4945\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0798 - val_loss: 177.4365\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8690 - val_loss: 165.1558\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4356 - val_loss: 159.4135\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3011 - val_loss: 165.9180\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3058 - val_loss: 170.0319\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1073 - val_loss: 177.8694\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9580 - val_loss: 178.9235\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9405 - val_loss: 169.3139\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6356 - val_loss: 157.3734\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1944 - val_loss: 164.8093\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1292 - val_loss: 170.1191\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.7936 - val_loss: 177.2478\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2790 - val_loss: 184.5466\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9352 - val_loss: 172.0570\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9952 - val_loss: 162.0147\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2320 - val_loss: 167.2754\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1134 - val_loss: 175.9774\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0897 - val_loss: 176.3609\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9015 - val_loss: 170.3304\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8640 - val_loss: 184.6062\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2250 - val_loss: 184.8708\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4802 - val_loss: 181.7540\n",
      "33/33 [==============================] - 0s 935us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.9164 - val_loss: 183.9040\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2771 - val_loss: 176.0880\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9863 - val_loss: 172.1850\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1430 - val_loss: 166.1663\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2767 - val_loss: 174.2593\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1395 - val_loss: 155.2112\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1870 - val_loss: 169.8608\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1425 - val_loss: 165.1670\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8978 - val_loss: 175.3628\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9339 - val_loss: 173.0978\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1323 - val_loss: 182.0502\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8982 - val_loss: 172.8903\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0363 - val_loss: 168.8434\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7328 - val_loss: 180.2485\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8752 - val_loss: 179.6365\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0645 - val_loss: 175.3369\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0720 - val_loss: 174.7068\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1492 - val_loss: 158.2971\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7508 - val_loss: 178.5685\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9760 - val_loss: 172.7128\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8893 - val_loss: 170.7847\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7309 - val_loss: 183.1974\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0893 - val_loss: 188.1257\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9460 - val_loss: 167.0364\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.9180 - val_loss: 180.7091\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8842 - val_loss: 185.6687\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1723 - val_loss: 184.4108\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2054 - val_loss: 196.3846\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1466 - val_loss: 171.6222\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1864 - val_loss: 184.6884\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6699 - val_loss: 176.9413\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0353 - val_loss: 178.2606\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7000 - val_loss: 188.3321\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.7279 - val_loss: 168.3622\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9105 - val_loss: 165.7400\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2139 - val_loss: 171.5604\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2271 - val_loss: 183.0484\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1191 - val_loss: 177.7610\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1135 - val_loss: 178.3674\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9112 - val_loss: 185.6295\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8861 - val_loss: 163.2954\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2065 - val_loss: 164.4183\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1136 - val_loss: 161.6454\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9471 - val_loss: 179.2926\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0748 - val_loss: 182.2296\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3146 - val_loss: 177.7731\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9015 - val_loss: 168.7938\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6548 - val_loss: 176.8407\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2093 - val_loss: 169.9096\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7716 - val_loss: 179.4064\n",
      "33/33 [==============================] - 0s 969us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 19.7994 - val_loss: 183.8791\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3255 - val_loss: 190.5634\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1425 - val_loss: 175.3422\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2315 - val_loss: 174.6821\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7941 - val_loss: 177.3043\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1727 - val_loss: 182.7833\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0513 - val_loss: 164.5167\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0742 - val_loss: 169.9325\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.8466 - val_loss: 167.5805\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9467 - val_loss: 176.7035\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7564 - val_loss: 182.8873\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1402 - val_loss: 176.7461\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1495 - val_loss: 190.0918\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8181 - val_loss: 189.0411\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9779 - val_loss: 174.0031\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2763 - val_loss: 170.8170\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.1118 - val_loss: 178.0253\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0332 - val_loss: 170.3395\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7324 - val_loss: 179.4263\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6730 - val_loss: 177.5346\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6952 - val_loss: 172.3649\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.8104 - val_loss: 166.3478\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8616 - val_loss: 168.3648\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.6202 - val_loss: 173.1965\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2385 - val_loss: 182.9197\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8514 - val_loss: 172.1595\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9208 - val_loss: 175.6006\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7058 - val_loss: 171.2946\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8657 - val_loss: 179.8134\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.7350 - val_loss: 174.0948\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.2791 - val_loss: 175.5206\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7691 - val_loss: 178.3748\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8203 - val_loss: 183.6915\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6603 - val_loss: 169.3674\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9185 - val_loss: 168.1337\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9810 - val_loss: 176.6382\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6521 - val_loss: 187.9981\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8476 - val_loss: 182.3516\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0543 - val_loss: 182.5393\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9717 - val_loss: 165.3739\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8627 - val_loss: 181.9075\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.8480 - val_loss: 178.7455\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5461 - val_loss: 177.8911\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0236 - val_loss: 197.5949\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0751 - val_loss: 190.5700\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1348 - val_loss: 179.9886\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5346 - val_loss: 166.5524\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2515 - val_loss: 178.3636\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7495 - val_loss: 184.4278\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9415 - val_loss: 183.5270\n",
      "33/33 [==============================] - 0s 929us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 20.1417 - val_loss: 165.9645\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9106 - val_loss: 184.8348\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0109 - val_loss: 178.4395\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6558 - val_loss: 171.9350\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.5843 - val_loss: 170.8745\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8148 - val_loss: 181.3787\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7336 - val_loss: 186.8430\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6232 - val_loss: 181.6848\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9025 - val_loss: 179.0688\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.6482 - val_loss: 184.6173\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7272 - val_loss: 179.2824\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6234 - val_loss: 165.4411\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7963 - val_loss: 179.4173\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9050 - val_loss: 191.1100\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9278 - val_loss: 185.4614\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1812 - val_loss: 184.6130\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9161 - val_loss: 193.3537\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.6551 - val_loss: 190.9533\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8491 - val_loss: 171.9691\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.8643 - val_loss: 179.6884\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0005 - val_loss: 192.1341\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0831 - val_loss: 203.7895\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2549 - val_loss: 190.9073\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0219 - val_loss: 180.4699\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4379 - val_loss: 160.5739\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.1358 - val_loss: 173.5978\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8418 - val_loss: 184.7029\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8211 - val_loss: 186.4948\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8877 - val_loss: 187.4673\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7397 - val_loss: 186.6826\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9462 - val_loss: 183.0955\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7670 - val_loss: 186.8338\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.5143 - val_loss: 184.4579\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7875 - val_loss: 170.9802\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9794 - val_loss: 163.0164\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 20.0007 - val_loss: 181.8522\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4487 - val_loss: 178.5074\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7100 - val_loss: 167.1646\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6036 - val_loss: 181.7318\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6132 - val_loss: 182.3111\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5893 - val_loss: 186.0788\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7051 - val_loss: 162.4693\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5371 - val_loss: 195.7692\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5574 - val_loss: 168.8379\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7055 - val_loss: 179.6532\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6699 - val_loss: 189.3595\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8613 - val_loss: 185.5255\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5525 - val_loss: 175.5081\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9820 - val_loss: 168.2607\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4708 - val_loss: 176.1339\n",
      "33/33 [==============================] - 0s 875us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.6428 - val_loss: 192.9976\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.9193 - val_loss: 180.4785\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.3971 - val_loss: 175.5678\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6161 - val_loss: 177.7404\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7854 - val_loss: 172.7794\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5269 - val_loss: 182.1542\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5494 - val_loss: 175.1276\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6560 - val_loss: 193.4562\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.4607 - val_loss: 188.5934\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2764 - val_loss: 197.9858\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7193 - val_loss: 174.1921\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.8713 - val_loss: 176.2134\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5963 - val_loss: 184.0348\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4302 - val_loss: 175.9205\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8222 - val_loss: 174.0781\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7205 - val_loss: 190.6312\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.2242 - val_loss: 172.4732\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5330 - val_loss: 187.2565\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6045 - val_loss: 174.2352\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5091 - val_loss: 169.2192\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.9118 - val_loss: 165.1913\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.0805 - val_loss: 175.4756\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6522 - val_loss: 162.8459\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5797 - val_loss: 176.2167\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4625 - val_loss: 188.2301\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.1159 - val_loss: 192.3061\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.0137 - val_loss: 167.4633\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1452 - val_loss: 180.6500\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9964 - val_loss: 180.2889\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.3047 - val_loss: 176.0102\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6070 - val_loss: 176.6084\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7436 - val_loss: 178.3015\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5215 - val_loss: 176.9104\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2858 - val_loss: 173.2218\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6265 - val_loss: 185.0014\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8998 - val_loss: 193.5212\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.7752 - val_loss: 174.0764\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6258 - val_loss: 175.7988\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6418 - val_loss: 176.8653\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3916 - val_loss: 183.4949\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4153 - val_loss: 188.2341\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6295 - val_loss: 174.3879\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.1083 - val_loss: 200.7076\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.9353 - val_loss: 194.3527\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8299 - val_loss: 173.4202\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5896 - val_loss: 188.1211\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4024 - val_loss: 169.9005\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3505 - val_loss: 184.5170\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5217 - val_loss: 183.0583\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.3879 - val_loss: 179.4736\n",
      "33/33 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.3273 - val_loss: 184.5661\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7235 - val_loss: 183.2544\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3122 - val_loss: 179.4358\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4739 - val_loss: 170.7825\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.9695 - val_loss: 174.5095\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3296 - val_loss: 177.0515\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3159 - val_loss: 176.2862\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6917 - val_loss: 181.0115\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.3068 - val_loss: 199.8326\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 20.3876 - val_loss: 196.1861\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20.4039 - val_loss: 189.3590\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4925 - val_loss: 176.6665\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5855 - val_loss: 175.0757\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3656 - val_loss: 180.6718\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.3722 - val_loss: 170.8253\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6336 - val_loss: 191.3447\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8508 - val_loss: 188.9120\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6548 - val_loss: 176.3830\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6930 - val_loss: 184.0613\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.1212 - val_loss: 181.2252\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4747 - val_loss: 173.6179\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4379 - val_loss: 171.2018\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.5870 - val_loss: 169.0700\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8935 - val_loss: 175.2559\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5346 - val_loss: 172.0912\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4457 - val_loss: 194.0250\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7498 - val_loss: 180.1431\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6234 - val_loss: 180.3528\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7808 - val_loss: 182.9034\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4425 - val_loss: 173.0958\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.7683 - val_loss: 177.3764\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2615 - val_loss: 174.6756\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4028 - val_loss: 182.2223\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3207 - val_loss: 187.5393\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3522 - val_loss: 173.2000\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5442 - val_loss: 166.3018\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4635 - val_loss: 167.3384\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5922 - val_loss: 190.4866\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.8212 - val_loss: 184.4697\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.4112 - val_loss: 178.0153\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.1767 - val_loss: 174.4229\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2465 - val_loss: 176.3030\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2654 - val_loss: 184.3984\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4344 - val_loss: 179.2454\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.4568 - val_loss: 190.0687\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3969 - val_loss: 169.7851\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2984 - val_loss: 181.3414\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.1412 - val_loss: 171.6917\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2855 - val_loss: 180.4621\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.0457 - val_loss: 172.3846\n",
      "33/33 [==============================] - 0s 934us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.2122 - val_loss: 172.5786\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3030 - val_loss: 176.4578\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3930 - val_loss: 171.3328\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.1633 - val_loss: 183.2798\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2481 - val_loss: 178.2301\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.2792 - val_loss: 179.7459\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.3042 - val_loss: 181.4818\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2171 - val_loss: 170.5001\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.1997 - val_loss: 172.9208\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.1152 - val_loss: 179.0569\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4052 - val_loss: 174.0737\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6288 - val_loss: 187.0215\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.4295 - val_loss: 167.2468\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.0790 - val_loss: 176.1729\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4006 - val_loss: 175.0009\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2966 - val_loss: 170.3415\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2922 - val_loss: 185.5224\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2436 - val_loss: 178.2331\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3306 - val_loss: 183.4316\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.1666 - val_loss: 173.6468\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3570 - val_loss: 178.3887\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.1863 - val_loss: 180.0390\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.1316 - val_loss: 173.5681\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3843 - val_loss: 190.5442\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.6757 - val_loss: 175.4501\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2048 - val_loss: 183.5494\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5420 - val_loss: 189.8118\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.3577 - val_loss: 181.6388\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.5621 - val_loss: 178.6580\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.5556 - val_loss: 191.0490\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2684 - val_loss: 172.8283\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4218 - val_loss: 189.4242\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.3366 - val_loss: 169.8379\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.6711 - val_loss: 173.9480\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2357 - val_loss: 172.6449\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.3127 - val_loss: 172.8511\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2435 - val_loss: 173.1839\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.1547 - val_loss: 177.9671\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.3605 - val_loss: 174.3913\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4170 - val_loss: 173.8369\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.2159 - val_loss: 182.9761\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2018 - val_loss: 177.3307\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 18.9441 - val_loss: 180.5750\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2408 - val_loss: 192.6950\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.1986 - val_loss: 186.4041\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.4242 - val_loss: 172.9583\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.0125 - val_loss: 185.8922\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19.2793 - val_loss: 167.8843\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19.2607 - val_loss: 178.1318\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.1926 - val_loss: 186.2888\n",
      "33/33 [==============================] - 0s 935us/step\n"
     ]
    }
   ],
   "source": [
    "model_2 = concrete_regression_model_2()\n",
    "\n",
    "mse_list_4 = []\n",
    "\n",
    "for i in range(50):\n",
    "    model_2.fit(predictors_normalized, target, validation_split=0.3, epochs=50)\n",
    "    predictions = model_2.predict(predictors_normalized) \n",
    "    mse = mean_squared_error(target, predictions)     \n",
    "    mse_list_4.append(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139.5225419360898, 104.73980415701607, 65.68252463465153, 74.03222456412945, 75.52530705230005, 78.77920644557274, 78.04983005633993, 79.62743640412042, 78.83659440110668, 76.80343176457902, 74.12442060430133, 82.26031659768434, 82.63395126064633, 73.7804578830254, 76.5578205039504, 78.99802067070661, 80.13034186242962, 76.8946685900263, 79.29481074871215, 76.72002375138477, 79.27798342313969, 72.64447683642342, 74.50853340802958, 75.02339069306754, 74.54131752022599, 70.91308294523554, 70.85830689713839, 72.64306073798892, 69.67861217812194, 73.55634391672652, 74.43311171065747, 67.65626533788495, 69.91828458361731, 67.14262918203747, 64.00375166618758, 68.47547356707983, 67.54097637106449, 67.85681138958397, 67.38645253221665, 66.74709113352196, 64.29057288638833, 64.82778339319019, 75.55050885357232, 68.545175826368, 67.3618748892834, 68.68585490016706, 66.22023145379107, 67.07522120141338, 64.89588955186139, 69.05151981570015]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(mse_list_4)\n",
    "print(len(mse_list_4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.48608645380914\n",
      "11.520621306973979\n"
     ]
    }
   ],
   "source": [
    "mean_of_mse_list_4 = np.mean(mse_list_4)\n",
    "std_of_mse_list_4 = np.std(mse_list_4)\n",
    "\n",
    "print(mean_of_mse_list_4)\n",
    "print(std_of_mse_list_4)\n",
    "\n",
    "# In my run I got mean = 56.693 and standard deviation = 29.424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got smaller mean in Part D of 56.693 compared to 56.799 in Part B. It is worth noting however that my standard deviation of 29.424 in Part D is smaller than my standard deviation of 36.299 in Part B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted concrete strength: 41.52 MPa\n"
     ]
    }
   ],
   "source": [
    "my_mix = {\n",
    "    'Cement': 198.6,\n",
    "    'Blast Furnace Slag': 132.4,\n",
    "    'Fly Ash': 0,\n",
    "    'Water': 192.0,\n",
    "    'Superplasticizer': 0,\n",
    "    'Coarse Aggregate': 978.4,\n",
    "    'Fine Aggregate': 825.5,\n",
    "    'Age': 360\n",
    "}\n",
    "\n",
    "# Create DataFrame and normalize it using the same parameters as training data\n",
    "my_mix_df = pd.DataFrame([my_mix])\n",
    "my_mix_normalized = (my_mix_df - predictors.mean()) / predictors.std()\n",
    "\n",
    "# Get prediction using normalized data\n",
    "prediction = model_2.predict(my_mix_normalized)\n",
    "print(f\"Predicted concrete strength: {float(prediction[0][0]):.2f} MPa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
